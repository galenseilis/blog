[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Galen Seilis",
    "section": "",
    "text": "Galen is a science and technology enthusiast dedicated to life-long learning. Through the application of ethics, reason, and observation, he believes we can tackle problems in medicine, the environment, economics, and exploration."
  },
  {
    "objectID": "posts/how-to-compile-python-on-linux/index.html",
    "href": "posts/how-to-compile-python-on-linux/index.html",
    "title": "How to Compile CPython on Debian-Based Linux",
    "section": "",
    "text": "This is a short blog post to remind myself how to compile CPython from its source.\nYou need to get the source files for Python as you need to give the C compiler (and other tools) the needed instructions for producing machine code. The CPython source is available on Github. Using git, you can download with\n$ git clone https://github.com/python/cpython.git\nYou should install build-essential which provides tooling for building Debian packages. This can be done with apt:\n$ sudo apt install build-essential\nNext install these assorted packages:\n$ sudo apt install libssl-dev zlib1g-dev libncurses5-dev libncursesw5-dev libreadline-dev libsqlite3-dev libgdbm-dev libdb5.3-dev libbz2-dev liblzma-dev libffi-dev\nHere is a brief description of each package:\n\n\n\nInstall\nPackage\nDescription\n\n\n\n\nlibssl-dev\nSecure Sockets Layer toolkit - development files\nThis package is part of the OpenSSL project’s implementation of the SSL and TLS crypographic protocols for secure communication over the internet.\n\n\nzlib1g-dev\nCompression library - development\nzlib is a library implementing the deflate compression method found in gzip and PKZIP.\n\n\nlibncurses5-dev\nTransitional pacakge for libncurses-dev\nPackage prociding libncurses5-dev.\n\n\nlibncursesw5-dev\nTransitional package for libncurses-dev\nPackage providing libncursesw5-dev.\n\n\nlibreadline-dev\nGNU readline and history libraries, development files\nThe GNU readline library aids in the consistency of user interface across discrete programs that need to provide a command line interace\n\n\nlibsqlite3-dev\nlibsqlite3-dev\nSQLite is a C library that implements an SQL database engine.\n\n\nlibgdbm-dev\nGNU dbm database routines (development files)\nGNU dbm (‘gdbm’) is a library of database functions that use extensible hashing and works similarly to the standard UNIX ‘dbm’ functions.\n\n\nlibdb5.3-dev\nBerkeley v5.3 Database Libraries [development]\nThis is the development package which contains headers and static libraries for the Berkely v5.3 database library\n\n\nlibbz2-dev\nHigh-quality block-sorting file compressor library - development\nStatic libraries and include files for the bzip2 compressor library\n\n\nliblzma-dev\nXZ-format compression library - development files\nXZ is the successor to the Lempel-Ziv/Markov-chain Algorithm compression format, which provides memory-hungry but powerful compressoin (often better than bzip2) and fast, easy decompression.\n\n\nlibffi-dev\nForeign Fucntion Interface library (development files)\nThis package contains the headers and static library files necessary for building programs which use libffi\n\n\n\nNow run the configuration tool that the Python dev’s have kindly prepared. It will prepare a makefile for everything you need to build CPython.\n$ ./configure --with-pydebug\nThe --with-pydebug tells configure to use a debugging hook.\nFinally, you can just run make.\n$ make\nThat’s pretty much it. If you want to silence the large standard output, you can add an -s. By default make will compile the first target specified in the make file, which for this project is actually the entirety of CPython itself. You can specify special build targets related to building, testing, installation, and other topics."
  },
  {
    "objectID": "posts/quantecon-1-scipy-submodules/index.html",
    "href": "posts/quantecon-1-scipy-submodules/index.html",
    "title": "QuantEcon 1 Scipy Submodules",
    "section": "",
    "text": "As someone with previous background in Python, I’ve been blasting my way through the basics of the Quantecon curricula. One of the joys of self-directed learning is that, with discipline, you can speed through familar material and really camp out with the new material. With that in mind, I’ve decided to further play with finding solutions (x-intercepts) of some single variable functions.\nFirst of all, let’s find ourselves an interesting function. I’ve chosen \\(f(x) = \\sin(x) \\exp(-x)\\) because I’ve always enjoyed its degradating oscillations, but also because I expect this equation to have solutions. Since any integer multiple \\(k\\) of \\(\\pi\\) will result in \\(\\sin(x) = 0\\) when \\(x = k \\pi\\), we know that \\(f(k \\pi) = 0\\) as well. While I’m quite late (or too early, depending on how you see it) for calculating \\(\\pi\\) on \\(\\pi\\) Day, let’s take \\(k = 1\\) to find \\(\\pi\\) anyway!\n\nBisection Method\nThe first method mentioned on QuantEcon is the bisection algorithm, which essentially treats finding solutions to a function as a binary search problem. There are two parameters that are needed to get started with the bisection algorithm, an initial lower bound and an initial upper bound on the search space. Not only do we need two such parameters, but our choice of these two numbers can change what solution is found. Let’s consider the following example where we look on the interval \\([-10, 10]\\).\n\nimport numpy as np\nfrom scipy.optimize import bisect\n# Define a single-variable function to find solutions in\nf = lambda x: np.sin(x) * np.exp(-x)\n# try out the bisection algorithm\nprint(bisect(f, -10, 10))\n\n0.0\n\n\nWe were looking for \\(x = \\pi\\), but we got \\(x = 0\\) instead. If there are multiple solutions within your search interval, the algorithm won’t necessarily converge on the one that you wanted, nor will it report to you there were multiple solutions. Knowing ahead of time that we’d like to calculate \\(\\pi\\), and that \\(3 &lt; \\pi &lt; 4\\), let’s rerun the bisection algorithm on \\([3, 4]\\).\n\nprint(bisect(f, 3, 4))\n\n3.1415926535901235\n\n\nThat gives us a value pretty close to \\(\\pi\\), correct to the \\(11\\)th digit anyway.\n\n\nNewton-Raphson method\nThe Newton-Raphson method is a calculus-based method that iteratively steps towards a solution. Like the bisection method, it requires a number decided ahead of time but this time this chosen number is an initial guess or starting point. Unlike the bisection method, the Newton-Raphson method does not have bounds set on the search so a continuous function over the real numbers can be searched indefinitely. To prevent the algorithm searching for too long, a hyperparameter limiting the number of iterations (steps) is included if a stable solution is not converged upon (default is \\(50\\) steps).\n\nfrom scipy.optimize import newton\n# Define a single-variable function to find solutions in\n# try out the Newton-Raphson algorithm\nprint(newton(f, 0.2))\n\n3.6499361606787994e-14\n\n\nWhile \\(x = 0.2\\) is not that far off from Pi, the local derivatives are going to point the steps to descend toward zero. Notice that the solution we got was not exactly zero, but rather the first solution found within a predefined tolerance of \\(1.48 \\times 10^{-8}\\). What you don’t see from the code is the that shape of the curve, which if you plot our function you’ll see there is a local maxima between \\(x = 0\\) and \\(x = \\pi\\) at \\(x = \\frac{\\pi}{4}\\). Relative to this hill, our estimate is analogous to a ball rolling in the direction of steepest descent. This analogy breaks down for solutions separated by a local minima as the method is not equivalent to steepest descent even though it is based on the local derivative. Another issue that can come about is picking an initial value close to an extrema because the results can be unstable, allowing incredibly large jumps across the domain. Therefore, we should be cautious about our choice of initial guess by doing some exploration of function’s properties before attempting to estimate the solution. Let’s retry with a more suitable initial value.\n\n# try out the Newton-Raphson algorithm\nprint(newton(f, np.pi / 4 + 1))\n\n3.1415926535897936\n\n\nThat is clearly closer to \\(\\pi\\) than \\(3.6499361606787994 \\times 10^{-14}\\), and being accurate for the first \\(16\\) digits suggests that it was more precise than the bisection algorithm under these parameters.\n\n\nBrent’s method\nThe QuantEcon course points out that Bisection is more robust (stable) than Newton-Raphson’s method, but it is also slower. An alternative approach that balances this tradeoff is Brent’s method which includes bounds and garantees solutions for computable functions. Let’s give this approach a try on our function on \\([3, 4]\\).\n\nfrom scipy.optimize import brentq\n# try out the Brent's algorithm\nprint(brentq(f, 3, 4))\n\n3.141592653589788\n\n\nLooks like this estimation of \\(\\pi\\) was correct for the first \\(13\\) digits, which was better than Bisection but worse than Newton-Raphson.\n\n\nPerformance comparison with timeit\nLast of all, it would be interesting to compare the time performance of each of these solution-finding approaches. Let’s do that with timeit.\n\nfrom timeit import timeit\nprint(timeit(stmt='bisect(f, 3, 4)',\\\n    globals={'bisect':bisect, 'f':f},\\\n    number=100000) / 100000)\nprint(timeit(stmt='newton(f, np.pi / 4 + 1)',\\\n    globals={'newton':newton, 'f':f, 'np':np},\\\n    number=100000) / 100000)\nprint(timeit(stmt='brentq(f, 3, 4)',\\\n    globals={'brentq':brentq, 'f':f},\\\n    number=100000) / 100000)\n\n0.00010017173054002341\n0.0001319278220400156\n2.3580086980000487e-05\n\n\nWe find under this setup that the slowest algorithm was the Newton-Raphson’s method, followed by the bisection method by a factor of \\(\\frac{1}{5}\\), and final Brent’s method being about an order of magnitude faster! So Brent’s method gave us more accurate digits in the solution, at least for \\(x = \\pi\\), and also performed faster than the other two methods. Does this mean that Brent’s method is always the best method? Not necessarily. We should be open to the possibility of tradeoffs not discussed on QuantEcon, as well as there being a panoply of algorithms out available in code repositories."
  },
  {
    "objectID": "posts/my-quarto-blog/index.html",
    "href": "posts/my-quarto-blog/index.html",
    "title": "My Quarto Blog",
    "section": "",
    "text": "I am switching to Quarto for my blog. My Jekyll blog is available here, and I might move some of the posts over to the new blog over time.\nCreating this blog was really easy. Was my Jekyll blog really complicated to setup? There were some technical hurdles around getting extra behaviour on my original blog, but overall it wasn’t extremely hard. Why am I switching to Quarto?\nWhat Quarto provides (that I want) is code execution followed by rendering the output of the code. I can put my code examples right into the blog post, and if something like a plot is produced then that plot will show on my blog.\nIn constrast, with Jekyll, I needed to\n\nmake the plot\nmove the plot to an images folder\nreference to the plot’s path in the blog post.\n\nIt wasn’t terrible, and it is possible that I just didn’t figure out how to make this easier with Jekyll, but it was quickly apparent to me that Quarto makes this easy.\nThis includes mermaid diagrams:\n\n\n\n\n\n---\ntitle: Example Git diagram\n---\ngitGraph\n   commit\n   commit\n   branch develop\n   checkout develop\n   commit\n   commit\n   checkout main\n   merge develop\n   commit\n   commit\n\n\n\n\n\n\nI can also easily prepare Graphiz diagrams provided that I supply some valid dot notation:\n\ndigraph finite_state_machine {\n    fontname=\"Helvetica,Arial,sans-serif\"\n    node [fontname=\"Helvetica,Arial,sans-serif\"]\n    edge [fontname=\"Helvetica,Arial,sans-serif\"]\n    rankdir=LR;\n    node [shape = doublecircle]; 0 3 4 8;\n    node [shape = circle];\n    0 -&gt; 2 [label = \"SS(B)\"];\n    0 -&gt; 1 [label = \"SS(S)\"];\n    1 -&gt; 3 [label = \"S($end)\"];\n    2 -&gt; 6 [label = \"SS(b)\"];\n    2 -&gt; 5 [label = \"SS(a)\"];\n    2 -&gt; 4 [label = \"S(A)\"];\n    5 -&gt; 7 [label = \"S(b)\"];\n    5 -&gt; 5 [label = \"S(a)\"];\n    6 -&gt; 6 [label = \"S(b)\"];\n    6 -&gt; 5 [label = \"S(a)\"];\n    7 -&gt; 8 [label = \"S(b)\"];\n    7 -&gt; 5 [label = \"S(a)\"];\n    8 -&gt; 6 [label = \"S(b)\"];\n    8 -&gt; 5 [label = \"S(a)\"];\n}\n\n\n\n\n\n\nfinite_state_machine\n\n\n\n0\n\n\n0\n\n\n\n2\n\n2\n\n\n\n0-&gt;2\n\n\nSS(B)\n\n\n\n1\n\n1\n\n\n\n0-&gt;1\n\n\nSS(S)\n\n\n\n3\n\n\n3\n\n\n\n4\n\n\n4\n\n\n\n8\n\n\n8\n\n\n\n6\n\n6\n\n\n\n8-&gt;6\n\n\nS(b)\n\n\n\n5\n\n5\n\n\n\n8-&gt;5\n\n\nS(a)\n\n\n\n2-&gt;4\n\n\nS(A)\n\n\n\n2-&gt;6\n\n\nSS(b)\n\n\n\n2-&gt;5\n\n\nSS(a)\n\n\n\n1-&gt;3\n\n\nS($end)\n\n\n\n6-&gt;6\n\n\nS(b)\n\n\n\n6-&gt;5\n\n\nS(a)\n\n\n\n5-&gt;5\n\n\nS(a)\n\n\n\n7\n\n7\n\n\n\n5-&gt;7\n\n\nS(b)\n\n\n\n7-&gt;8\n\n\nS(b)\n\n\n\n7-&gt;5\n\n\nS(a)\n\n\n\n\n\n\n\n\nThis is definitely desired behaviour."
  },
  {
    "objectID": "posts/rust-execution-for-quarto/index.html",
    "href": "posts/rust-execution-for-quarto/index.html",
    "title": "Executable Rust Code in Quarto",
    "section": "",
    "text": "The following is a Lua filter which looks through a qmd file for Rust code associated with {rust}, compiles that code using rustc, runs the compiled Rust program and collects its output, and inserts the output to be rendered by pandoc.\nlocal io = require(\"io\")\nlocal os = require(\"os\")\nlocal tempfile = require(\"os\").tmpname\nlocal log_file\n\n-- Function to initialize the log file\nlocal function init_log()\n  log_file = io.open(\"rust_executor_debug.log\", \"w\")\nend\n\n-- Function to log messages to file and stderr\nlocal function log(...)\n  local args = {...}\n  for i = 1, #args do\n    args[i] = tostring(args[i])\n  end\n  local message = table.concat(args, \" \")\n  if log_file then\n    log_file:write(message .. \"\\n\")\n    log_file:flush()\n  end\n  io.stderr:write(message .. \"\\n\")\n  io.stderr:flush()\nend\n\n-- Helper function to execute Rust code and return the output\nlocal function execute_rust_code(code)\n  local temp_file = tempfile() .. \".rs\"\n  log(\"Temporary Rust file:\", temp_file)\n  local source_file, err = io.open(temp_file, \"w\")\n  if not source_file then\n    log(\"Failed to create source file:\", err)\n    error(\"Failed to create source file: \" .. err)\n  end\n\n  source_file:write(code)\n  source_file:close()\n\n  local temp_bin = tempfile()\n  log(\"Temporary binary file:\", temp_bin)\n\n  local compile_command = \"rustc \" .. temp_file .. \" -o \" .. temp_bin .. \" 2&gt;&1\"\n  log(\"Compile Command:\", compile_command)\n  local compile_pipe = io.popen(compile_command)\n  local compile_output = compile_pipe:read(\"*a\")\n  local compile_result = compile_pipe:close()\n\n  if compile_result ~= true then\n    os.remove(temp_file)\n    log(\"Rust compilation failed. Output:\", compile_output)\n    error(\"Rust compilation failed. Output: \" .. compile_output)\n  end\n\n  local exec_command = temp_bin .. \" 2&gt;&1\"\n  log(\"Exec Command:\", exec_command)\n  local exec_pipe = io.popen(exec_command)\n  local output = exec_pipe:read(\"*a\")\n  exec_pipe:close()\n\n  local ok, rm_err = pcall(function()\n    os.remove(temp_file)\n    os.remove(temp_bin)\n  end)\n  if not ok then\n    log(\"Failed to clean up temporary files:\", rm_err)\n    error(\"Failed to clean up temporary files: \" .. rm_err)\n  end\n\n  log(\"Output:\", output)\n  return output\nend\n\nlocal echo_global = true\n\nfunction Meta(meta)\n  if meta.echo ~= nil then\n    echo_global = pandoc.utils.stringify(meta.echo) == \"true\"\n  end\nend\n\n-- Lua filter function\nfunction CodeBlock(elem)\n  if not log_file then\n    init_log()\n  end\n\n  local is_rust_code = elem.attr.classes:includes(\"{rust}\")\n  if is_rust_code then\n    log(\"Processing Rust code block\")\n    local output = execute_rust_code(elem.text)\n    output = output:gsub(\"%s+$\", \"\")\n    local blocks = {}\n\n    if echo_global then\n      -- Render Rust code as a formatted block\n      table.insert(blocks, pandoc.CodeBlock(elem.text, {class=\"rust\"}))\n    end\n\n    -- Always return the output\n    table.insert(blocks, pandoc.Para(pandoc.Str(output)))\n\n    return blocks\n  else\n    log(\"Skipping non-Rust code block\")\n  end\nend\n\n-- Ensure log file is closed properly at the end\nfunction Pandoc(doc)\n  if log_file then\n    log_file:close()\n  end\n  return doc\nend\nLet’s try some examples.\nHere is some Rust code that will be executed and rendered.\nfn main() {\n        println!(\"Galen Seilis is learning Rust!\");\n        println!(\"Time to get Rusty!\");\n}\nGalen Seilis is learning Rust!\nTime to get Rusty!\nNow let us try some Rust code that will not be executed.\nfn main() {\n    println!(\"Meow\");\n}\nNow let us run a longer example from Rust by Example.\nfn main() {\n    // Integer addition\n    println!(\"1 + 2 = {}\", 1u32 + 2);\n\n    // Integer subtraction\n    println!(\"1 - 2 = {}\", 1i32 - 2);\n    // TODO ^ Try changing `1i32` to `1u32` to see why the type is important\n\n    // Scientific notation\n    println!(\"1e4 is {}, -2.5e-3 is {}\", 1e4, -2.5e-3);\n\n    // Short-circuiting boolean logic\n    println!(\"true AND false is {}\", true && false);\n    println!(\"true OR false is {}\", true || false);\n    println!(\"NOT true is {}\", !true);\n\n    // Bitwise operations\n    println!(\"0011 AND 0101 is {:04b}\", 0b0011u32 & 0b0101);\n    println!(\"0011 OR 0101 is {:04b}\", 0b0011u32 | 0b0101);\n    println!(\"0011 XOR 0101 is {:04b}\\n\\n\\n\", 0b0011u32 ^ 0b0101);\n    println!(\"1 &lt;&lt; 5 is {}\", 1u32 &lt;&lt; 5);\n    println!(\"0x80 &gt;&gt; 2 is 0x{:x}\", 0x80u32 &gt;&gt; 2);\n\n    // Use underscores to improve readability!\n    println!(\"One million is written as {}\", 1_000_000u32);\n}\n1 + 2 = 3\n1 - 2 = -1\n1e4 is 10000, -2.5e-3 is -0.0025\ntrue AND false is false\ntrue OR false is true\nNOT true is false\n0011 AND 0101 is 0001\n0011 OR 0101 is 0111\n0011 XOR 0101 is 0110\n\n\n\n1 &lt;&lt; 5 is 32\n0x80 &gt;&gt; 2 is 0x20\nOne million is written as 1000000\nIn the current state there are a couple of glaring issues I have with this implementation. The first is that Rust code blocks will be run regardless of whether echo: false is used. The second is that all the outputs are being rendered on a single, notwithstanding Quarto’s line wrapping.\nThere is also an enhancement which is desirable, which is to render other types of things from Rust that are not just plaintext. Instead of developing this kind of functionality myself, it would make sense to take a closer look at integrating tools such as the Evcxr Jupyter kernel."
  },
  {
    "objectID": "posts/flask-dynamic-url/index.html",
    "href": "posts/flask-dynamic-url/index.html",
    "title": "Dynamic URLs in Flask",
    "section": "",
    "text": "In a previous post I showed how to start the most basic Flask web application. In this post I show a dynamic URL which renders content that depends on using the URL as user input. The mathematical function known as factorial is defined as\n\\[n! \\triangleq \\prod_{i=1}^n i\\] when \\(i \\geq 1\\) and when \\(n=0\\) then \\(0! \\triangleq 1\\). We will set a dynamic URL which takes an integer for which the factorial will be calculated and displayed. We can specify this by passing '/factorial/&lt;int:number&gt;'. The prefix /factorial/ is just to remind us that we’re calculating the factorial of a number. The angle brackets &lt;TYPE:...&gt; indicate that something is unspecified input in between the brackets with type TYPE. In this case we want &lt;int: ...&gt; because the factorial function (not to be confused with its generalizations, like the gamma function) is defined only for non-negative integers. It is natural to use number since we expect a number, but other names are possible for this.\nfrom math import factorial\n\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.route('/factorial/&lt;int:number&gt;')\ndef calculate_factorial(number):\n    return str(factorial(number))\n\nif __name__ == '__main__':\n    app.run(debug=True)\nThat’s it. We’re just taking the number, calculating its factorial, casting the result to a string, and returning it. Flask takes care of the rest."
  },
  {
    "objectID": "posts/flask-display-image/index.html",
    "href": "posts/flask-display-image/index.html",
    "title": "Fetching from a URL and Displaying an Image Using Flask",
    "section": "",
    "text": "In this post I am going to show a Flask application which takes an integer and searches the Magic the Gathering database for an image of a corresponding card whose “multiverse ID” is the same as the given number.\nI used the requests package to get the image content. Supposing you get the content back, which will result in a response status code of 200, the image will still need to be converted into a memory binary stream. That’s where io.BytesIO comes in handy. Once the stream is prepared, the flask.send_file function can be used to prepare the rendered page content containing the file.\nfrom flask import Flask, send_file\nimport requests\nfrom io import BytesIO\n\napp = Flask(__name__)\n\n@app.route('/card/&lt;int:card_id&gt;')\ndef display_image(card_id):\n    # The URL of the image you want to display\n    image_url = f'https://gatherer.wizards.com/Handlers/Image.ashx?multiverseid={card_id}&type=card'\n\n    # Fetch the image from the URL\n    response = requests.get(image_url)\n\n    # Check if the request was successful\n    if response.status_code == 200:\n        # Create an in-memory binary stream of the image\n        image_stream = BytesIO(response.content)\n\n        # Send the image as a response\n        return send_file(image_stream, mimetype='image/png')\n    else:\n        # Handle the error case\n        return \"Failed to retrieve image\", response.status_code\n\nif __name__ == '__main__':\n    app.run(debug=True)\nThis app should allow you to input different numbers into the URL which then will render an Magic the Gathering card image, or will give an error."
  },
  {
    "objectID": "posts/flask-html-templates/index.html",
    "href": "posts/flask-html-templates/index.html",
    "title": "HTML Templates in Flask",
    "section": "",
    "text": "In this post we will not only have dynamic URLs, but start loading HTML templates. In the last post I wrote on Flask I used the factorial function. In this post we’ll take a number and GET/POST different templates depending on whether the input number is a prime number.\nTo check that a number is prime we can first check whether the candidate is less than 2. For natural numbers the number 2 is the smallest prime.\n\n\n\n\n\n\nNote\n\n\n\nIn the complex numbers, \\(\\mathbb{C}\\), the number 2 is not a “Gaussian prime”. It can be factored:\n\\[2 = (1 + i) (1 - i))\\]\n\n\nThe next criterion is that we only need to check whether there exists a natural number \\(k\\) such that \\(k^2 &lt; n\\) and \\(k | n\\). If such a number \\(k\\) does not exist, then \\(n\\) is a prime number.\nIn this example I prepared two templates:\n\ntemplates/example_is_prime.html\ntemplates/example_is_not_prime.html\n\nThe directory templates is in the same directory that the Flask application will be run. In example_is_prime.html I put\n&lt;h1&gt;The number {{ number }} is a prime!&lt;/h1&gt;\nand in example_is_not_prime.html I put\n&lt;h1&gt;The number {{ number }} is not a prime!&lt;/h1&gt;\nNote that neither of these files have the usual preamble that you’d find in an index.html file. That’s taken care of behind the scenes. You can also see { number } which specifies a variable name that is expected to come from render_template.\nfrom flask import Flask, render_template\n\ndef is_prime(n):\n    if n &lt; 2:\n        return False\n    i = 2\n    while i*i &lt;= n:\n        if n % i == 0:\n            return False\n        i += 1\n    return True\n\n\napp = Flask(__name__)\n\n@app.route('/primality/&lt;int:number&gt;')\ndef display_primarily(number):\n    if is_prime(number):\n        return render_template('example_is_prime.html', number=number)\n    else:\n        return render_template('example_is_not_prime.html', number=number)\n\nif __name__ == '__main__':\n    app.run(debug=True)\nWhen you run this application you’ll be able to enter various numbers in, and what will be displayed is a sentence telling you whether the number you provided in the URL is a prime number of note."
  },
  {
    "objectID": "posts/c-execution-for-quarto/index.html",
    "href": "posts/c-execution-for-quarto/index.html",
    "title": "Executable C Code in Quarto",
    "section": "",
    "text": "In Executable Rust Code in Quarto I made a rough implementation of having Rust code compiled and its output rendered.\nWith some small adjustments we can do the same for other languages, including C. Here is a “Hello, World” example.\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Hello, World!\\n\");\n    return 0;\n}\nHello, World!\nSimilar to the lessons learned from the Rust implementation, there is plausibly a better implementation with an entirely different starting point."
  },
  {
    "objectID": "posts/quantecon-2-numba/index.html",
    "href": "posts/quantecon-2-numba/index.html",
    "title": "QuantEcon 1 Numba",
    "section": "",
    "text": "Introduction\nNumba is a Python library that provides an open source just-in-time compiler that allows a coder to mark selected parts of their code to be compiled for faster execution. As someone interested in computation at any scale, from calculating \\(13 \\times 19\\) (mental arithmetic is not my forte) to analyzing the behaviour of tens of thousands of genes or hundreds of thousands of IP addresses. I am not one to squeeze every inch of performance out of something small that was only meant to run once as a proof of concept, but it can be worth speeding up tasks that are either huge or will be repeated.\nLet’s get into how to use Numba – hang on! Why not just use compiled languages like C, C++ or FORTRAN? Well, herein lies one of meta-problems of development that requires some optimization. Coding in Python is useful for quickly coding up proofs of concept, but properties like its dynamic typing slow it down compared to memory-managed code in C. Coding in C will give a faster execution for the same code, but will often require more time and degugging to get ready for deployment. Using Python with Numba is an attempt to get the best of both worlds, and in practice is not much slower than software compiled from well-written low-level languages.\n\n\nJIT\nThe first way we can use Numba to speed up our code is by compiling a function so that future executions can use the compiled version, removing the need to compile at runtime. Let’s take a function that gives us the first n Fibonnacci numbers, and see how it performs.\n\nimport numpy as np\nfrom timeit import timeit\n\ndef fib(n):\n    '''\n    Adjusted from:\n    https://lectures.quantecon.org/py/numba.html\n    https://en.wikipedia.org/wiki/Fibonacci_number\n    https://www.geeksforgeeks.org/program-for-nth-fibonacci-number/\n    '''\n\n    if n == 1:\n        return np.ones(1)\n    elif n &gt; 1:\n        x = np.empty(n)\n        x[0] = 1\n        x[1] = 1\n        for i in range(2,n):\n            x[i] =  x[i-1] + x[i-2]\n        return x\n    else:\n        print('WARNING: Check validity of input.')\n\nprint(timeit('fib(10)', globals={'fib':fib}))\n\n2.0311123809988203\n\n\nRunning the above code on my laptop gives around 2 seconds to run the function \\(1000000\\) times according to timeit, which is reasonable for small \\(n\\) but let’s see if we can speed this up with the Numba’s jit.\n\nfrom numba import jit\nimport numpy as np\nfrom timeit import timeit\n\ndef fib(n):\n    '''\n    ARGUMENTS:\n    n: Max index to calculate Fibonacci numbers up to (int)\n    RETURNS\n    x: Array of Fibonnacci numbers (numpy.ndarray)\n\n    NOTES:\n    Adjusted from:\n    https://lectures.quantecon.org/py/numba.html\n    https://en.wikipedia.org/wiki/Fibonacci_number\n    https://www.geeksforgeeks.org/program-for-nth-fibonacci-number/\n    '''\n\n    if n == 1:\n        return np.ones(1)\n    elif n &gt; 1:\n        x = np.empty(n)\n        x[0] = 1\n        x[1] = 1\n        for i in range(2,n):\n            x[i] =  x[i-1] + x[i-2]\n        return x\n    else:\n        print('WARNING: Check validity of input.')\n\nfib = jit(fib)\n\nprint(timeit('fib(10)', globals={'fib':fib}))\n\n0.6980576210007712\n\n\nRunning the above code with jit brought the execution time down to about 0.7 seconds, which is faster than the original function.\n\n\nVectorizing\nAnother approach to speeding up code is vectorizing, where multiple operations are applied to each entry directly instead of producing multiple intermediate arrays as operations are applied. Originally I had wanted to use our fib function, but I quickly learned that it is not vectorizable because it cannot be made into a universal function. For a function to be universal, it is necessary that they map scalars into scalers, and map arrays into arrays. With that in mind, we’ll vectorize a suitable function to show how the time performance is improved. Let’s start by timing the unvectorized function.\nimport numpy as np\nimport quantecon as qe\n\ndef f(x, y):\n    return np.exp(np.abs(x -y**3)) *  np.cos(x**2 + y**2)\n\n# generate data\ngrid = np.linspace(-3, 3, 1000)\nx, y = np.meshgrid(grid, grid)\n\nstart = qe.util.tic()\nf(x, y)\nend = qe.util.toc()\nOn my machine the execution time was about \\(0.05\\) seconds, which isn’t half-bad by itself. Not let’s run the same code in vectorized form.\nfrom numba import vectorize\nimport numpy as np\nimport quantecon as qe\n\n@vectorize\ndef f(x, y):\n    return np.exp(np.abs(x -y**3)) *  np.cos(x**2 + y**2)\n\n# generate data\ngrid = np.linspace(-3, 3, 1000)\nx, y = np.meshgrid(grid, grid)\n\nf(x,y) # precompile\n\nstart = qe.util.tic()\nf(x, y)\nend = qe.util.toc()\nThis vectorized form took about \\(0.0042\\) seconds to execute, which is about \\(12\\) times faster! This is a clear demonstration that vectorizing functions is worthwhile as scalability becomes an issue.\nBecause the vectorization of this function means that each element of the array is calculated independently, we can further attempt to speed this calculation up by calculating elements in parallel! We do that by telling the decorator the element types (we’ll use float64), and that the target is function should be done in parallel.\nfrom numba import vectorize\nimport numpy as np\nimport quantecon as qe\n\n@vectorize('float64(float64, float64)', target='parallel')\ndef f(x, y):\n    return np.exp(np.abs(x -y**3)) *  np.cos(x**2 + y**2)\n\n# generate data\ngrid = np.linspace(-3, 3, 1000)\nx, y = np.meshgrid(grid, grid)\n\nf(x,y) # precompile\n\nstart = qe.util.tic()\nf(x, y)\nend = qe.util.toc()\nThis last acceleration to make the calculations parallel squeezed the execution time down to \\(0.0031\\) seconds. This is only \\(0.0011\\) seconds faster than without the parallel execution, but still a worthwhile addition to the toolkit for doing independent calculations.\n\n\nConclusion\nUsing Numba allows us an easy way to increase the performance of functions in Python without going to a lower-abstraction language such as C or FORTRAN. Some functions will be more suitable to @jit than @vectorize based on the type of operations and whether the function is universal (or can be made into a universal function). These accelerations in performance becomes increasingly valuable as the amount of data being processed becomes large!"
  },
  {
    "objectID": "posts/starting-data-science/index.html",
    "href": "posts/starting-data-science/index.html",
    "title": "Starting Data Science",
    "section": "",
    "text": "I’ve been thinking about Data Science lately, and I recently watched a YouTube video describing how to get started learning prerequisite knowledge for this field. While I am skeptical of the use of buzzwords, I think data science does reflect a loose collection of ideas and tools that are interesting and useful. Some of these subtopics include statistics, algorithms, databases, machine learning, and other miscellaneous topics within computer science and mathematics. I’m not partial to the term, but I am to the associated skillset.\nIn the interest of learning this subject in a structured way, I am going to go through the curricula suggested by Giles McMullen-Klein. I’ll modify it as it suites my needs or interests, but it serves as a simple template to get started with."
  },
  {
    "objectID": "posts/cpp-execution-for-quarto/index.html",
    "href": "posts/cpp-execution-for-quarto/index.html",
    "title": "Executable C++ Code in Quarto",
    "section": "",
    "text": "In Executable Rust Code in Quarto I made a rough implementation of having Rust code compiled and its output rendered.\nWith some small adjustments we can do the same for other languages, including C++. Here is a “Hello, World” example.\n#include &lt;iostream&gt;\n\nint main() {\n    std::cout &lt;&lt; \"Hello, World!\" &lt;&lt; std::endl;\n    return 0;\n}\nHello, World!\nSimilar to the lessons learned from the Rust implementation, there is plausibly a better implementation with an entirely different starting point."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Seilis, Galen. The Importance of Partial Pooling with Northern Health Data. Research and Knowledge Translation Newsletter\n\n\nSeilis, Galen. Project: Advanced Analytics. Research and Knowledge Translation Newsletter."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Basic Error Handling In Flask\n\n\n\n\n\n\nPython\n\n\nFlask\n\n\nWeb Applications\n\n\nError Handling\n\n\n\n\n\n\n\n\n\nJul 29, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nHello World, In Flask\n\n\n\n\n\n\nPython\n\n\nFlask\n\n\nWeb Applications\n\n\n\n\n\n\n\n\n\nJul 29, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nHTTP Methods in Flask\n\n\n\n\n\n\nPython\n\n\nFlask\n\n\nWeb Applications\n\n\nURL\n\n\nHTTP\n\n\nHTTP Methods\n\n\n\n\n\n\n\n\n\nJul 29, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nHTML Templates in Flask\n\n\n\n\n\n\nPython\n\n\nFlask\n\n\nWeb Applications\n\n\nURL\n\n\nHTML Templates\n\n\n\n\n\n\n\n\n\nJul 29, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nFetching from a URL and Displaying an Image Using Flask\n\n\n\n\n\n\nPython\n\n\nFlask\n\n\nWeb Applications\n\n\nURL\n\n\nRequests\n\n\nImages\n\n\n\n\n\n\n\n\n\nJul 29, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nDynamic URLs in Flask\n\n\n\n\n\n\nPython\n\n\nFlask\n\n\nWeb Applications\n\n\nURL\n\n\n\n\n\n\n\n\n\nJul 29, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nCreating URL using url_for in Flask\n\n\n\n\n\n\nPython\n\n\nFlask\n\n\nWeb Applications\n\n\nURL\n\n\n\n\n\n\n\n\n\nJul 29, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nBuild and Run a Rust Project from Quarto Using Python\n\n\n\n\n\n\nRust\n\n\nQuarto\n\n\nPython\n\n\nCargo\n\n\nrustc\n\n\n\n\n\n\n\n\n\nJul 29, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nExecutable C++ Code in Quarto\n\n\n\n\n\n\nQuarto\n\n\nC++\n\n\nLua\n\n\nPandoc\n\n\n\n\n\n\n\n\n\nJul 28, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nExecutable C Code in Quarto\n\n\n\n\n\n\nQuarto\n\n\nC\n\n\nLua\n\n\nPandoc\n\n\n\n\n\n\n\n\n\nJul 28, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nExecutable Rust Code in Quarto\n\n\n\n\n\n\nQuarto\n\n\nRust\n\n\nLua\n\n\nPandoc\n\n\n\n\n\n\n\n\n\nJul 26, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Compile CPython on Debian-Based Linux\n\n\n\n\n\n\nPython\n\n\nCPython\n\n\nC\n\n\ncompilation\n\n\nmake\n\n\nDebian\n\n\nLinux\n\n\n\n\n\n\n\n\n\nJul 25, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nMy Quarto Blog\n\n\n\n\n\n\nblog\n\n\nQuarto\n\n\nJekyll\n\n\nMermaid\n\n\nGraphviz\n\n\ndot\n\n\n\n\n\n\n\n\n\nJul 21, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nCombining Kedro with Rye\n\n\n\n\n\n\nKedro\n\n\nRye\n\n\nPython\n\n\nProject Management\n\n\nPackage Management\n\n\n\n\n\n\n\n\n\nJul 1, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nA Python CLI Example to Log the Execution Trace\n\n\n\n\n\n\nComputer Programming\n\n\nPython\n\n\nTracing\n\n\nScripting\n\n\nCLI\n\n\n\n\n\n\n\n\n\nJan 31, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nAutomorphism Orbits of Graphlets\n\n\n\n\n\n\nMath\n\n\nGraph Theory\n\n\nGraphlets\n\n\nAutomorphisms\n\n\nAutomorphism Orbits\n\n\nAutomorphism Orbits of Graphlets\n\n\nIsomorphisms\n\n\nGraphs\n\n\nRelations\n\n\nBinary Relations\n\n\nSets\n\n\nVertices\n\n\nEdges\n\n\nSubsets\n\n\nCartesian Products\n\n\nNetworks\n\n\ndirected Graphs\n\n\nDigraphs\n\n\nSigned Graphs\n\n\nWeighted Graphs\n\n\nSimple Graphs\n\n\nFunctions\n\n\nInjective Functions\n\n\nSurjective Functions\n\n\nBijective Functions\n\n\nGraph Isomorphism\n\n\nGraph Automorphisms\n\n\nEquivalence Relations\n\n\nReflexive Relations\n\n\nSymmetric Relations\n\n\nTransitive Relations\n\n\nEquivalence Classes\n\n\nVertex Orbit Automorphisms\n\n\nPermutation Groups\n\n\n\n\n\n\n\n\n\nMar 3, 2023\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Plot a Basic Pie Chart Of Taxa At A Given Taxonomic Rank Using Pandas And Matplotlib\n\n\n\n\n\n\nPython\n\n\nVolunteer\n\n\niNaturalist\n\n\nData\n\n\nPlotting\n\n\nMatplotlib\n\n\nPandas\n\n\nCitizen Science\n\n\n\n\n\n\n\n\n\nMar 16, 2022\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nUnzip Your iNaturalist Observations On A Ubuntu System\n\n\n\n\n\n\nBASH\n\n\nVolunteer\n\n\niNaturalist\n\n\nData\n\n\nCitizen Science\n\n\nLinux\n\n\nUbuntu\n\n\n\n\n\n\n\n\n\nMar 16, 2022\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nQuantEcon 1 Numba\n\n\n\n\n\n\nPython\n\n\nScipy\n\n\nNumPy\n\n\ntimeit\n\n\noptimization\n\n\nNumba\n\n\n\n\n\n\n\n\n\nApr 9, 2019\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nQuantEcon 1 Scipy Submodules\n\n\n\n\n\n\nPython\n\n\nScipy\n\n\nNumPy\n\n\nscipy.optimize\n\n\nNewton Raphson method\n\n\nBrents method\n\n\ntimeit\n\n\nbisect method\n\n\noptimization\n\n\n\n\n\n\n\n\n\nMar 28, 2019\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nStarting Data Science\n\n\n\n\n\n\nData Science\n\n\n\n\n\n\n\n\n\nMar 23, 2019\n\n\nGalen Seilis\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/pie-chart-inaturalist/index.html",
    "href": "posts/pie-chart-inaturalist/index.html",
    "title": "How to Plot a Basic Pie Chart Of Taxa At A Given Taxonomic Rank Using Pandas And Matplotlib",
    "section": "",
    "text": "Note\n\n\n\nThis post was migrated from my iNaturalist journal to my Jekyll blog on 2023-02-26. It was then migrated to my Quarto blog on 2024-07-27.\n\n\nSuppose you have an exported CSV of iNaturalist observations, observations-&lt;ID&gt;.csv.\nTo follow this tutorial you will have to have Python installed, and the Matplotlib and Pandas packages installed. Pandas is not necessary, but it makes things convenient enough that I recommend using it here. In other contexts you may wish to plot pie charts without Pandas.\nAssuming you have PIP installed, you can install Pandas and Matplotlib as follows:\npip install matplotlib pandas\nAlthough, since Pandas actually uses Matplotlib as a dependency for plotting, it might suffice to simply use:\npip install pandas\nNext, you must create a script file with the *.py extension. We can do fancier things with paths, but let us create the file pie_taxa.py using BASH.\ntouch pie_taxa.py\nNow let us write some lines of code in pie_taxa.py. First we need to import the required packages.\nimport matplotlib.pyplot as plt\nimport pandas as pd\nNext we can load our data using the pd.read_csv function, which assumes a CSV format by default. It has many other parameters, including changing the delimiter (see the docs), but we are fine with the defaults here.\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndf = pd.read_csv(\"observations-&lt;ID&gt;.csv\")\nNow, as if by magic (but actually the hard work of software developers), we can create the plot in a single line of code. Let us do it for the kingdom level, which will require us knowing that this is represented by the taxon_kingdom_name column in our data file.\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndf = pd.read_csv(\"observations-&lt;ID&gt;.csv\")\ndf['taxon_kingdom_name'].value_counts().plot.pie()\nThere are a few things going on in the previous line of code. First is that df['taxon_kingdom_name'] has selected only the taxon_kingdom_name column. This is next passed to the value_counts() which counts the occurrences of each kingdom in that column and returns a Pandas series object with this information, and then we finally call the plot.pie method on this series object which… well… makes the pie chart.\nIf you run the code at this point you may be surprised to not actually see a plot appear anywhere. If you ran the code from the command line you might have seen something like &lt;AxesSubplot:ylabel='taxon_kingdom_name'&gt;. This is because creating the instructions of what goes on the drawing canvas is different from graphically rendering it. In order to do that, we can call plt.show().\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndf = pd.read_csv(\"observations-&lt;ID&gt;.csv\")\ndf['taxon_kingdom_name'].value_counts().plot.pie()\nplt.show()\nRunning the above, you should see a window pop up. It has various settings for resizing, reshaping, zooming, and saving your figure.\nWhat if you didn’t want to look at Kingoms, but rather orders, or families, etc? You would simply use a different column instead of taxon_kingdom_name. Here is a table of these similar columns:\n\n\n\nTaxonomic Rank\n\n\n\n\ntaxon_kingdom_name\n\n\ntaxon_phylum_name\n\n\ntaxon_subphylum_name\n\n\ntaxon_superclass_name\n\n\ntaxon_class_name\n\n\ntaxon_subclass_name\n\n\ntaxon_superorder_name\n\n\ntaxon_order_name\n\n\ntaxon_suborder_name\n\n\ntaxon_superfamily_name\n\n\ntaxon_family_name\n\n\ntaxon_subfamily_name\n\n\ntaxon_supertribe_name\n\n\ntaxon_tribe_name\n\n\ntaxon_subtribe_name\n\n\ntaxon_genus_name\n\n\ntaxon_genushybrid_name\n\n\ntaxon_species_name\n\n\ntaxon_hybrid_name\n\n\ntaxon_subspecies_name\n\n\ntaxon_variety_name\n\n\ntaxon_form_name\n\n\n\nHappy plotting."
  },
  {
    "objectID": "posts/flask-basic-error-handling/index.html",
    "href": "posts/flask-basic-error-handling/index.html",
    "title": "Basic Error Handling In Flask",
    "section": "",
    "text": "Flask provides support for error handling, including defining custom errors. When an error occurs which is not otherwise defined, the default error code is 500 (internal server error).\nIn this post I will show a minimal example of using a predefined code for error handling in a Flask application.\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.errorhandler(404)\ndef page_not_found(error):\n    return 'This page does not exist (DNE)', 404\n\nif __name__ == '__main__':\n    app.run(debug=True)\nIn the above code we picked the classic 404 error, which is reserved for when the page cannot be reached. XKCD has an appropriate entry on this topic."
  },
  {
    "objectID": "posts/hello-world-flask/index.html",
    "href": "posts/hello-world-flask/index.html",
    "title": "Hello World, In Flask",
    "section": "",
    "text": "Ths post shows a relatively minimal example of using Flask to develop of web application. This application will only run locally, but it is otherwise a bona fide web application.\nfrom flask import Flask # 1\n\napp = Flask(__name__) # 2\n\n@app.route('/') # 3\ndef hello_world(): # 4\n    return 'Hello, World' # 5\n\nif __name__ == '__main__': # 6\n    app.run(debug=True) # 7\n\nImport the Flask class which is the central data structure for defining a Flask application.\nWe pass in __name__, which is the name of the current module, which helps Flask determine the root path for the application. The Flask application knowing what is defined as the root path will allow the application to find resources such as templates and static files.\nThis decorator will bind a URL, which in this case is simply /, root, to a function. When a user visits this URL, the function will be executed.\nDeclare the function we want to have run when a user visits the given URL.\nReturn 'Hello, World'.\nConditional to run the application when the module script is run directly.\nRun the FLask web server. The debug=True parameter assignment enables a debugging mode which provides information about any error messages and automatic restarts. The automatic restarts may occur when changes in the source code of the application are detected.\n\nWhen you run the application you’ll find that it is locally hosted at some port (http://127.0.0.1/&lt;SOME_PORT&gt;)."
  },
  {
    "objectID": "posts/flask-http-methods/index.html",
    "href": "posts/flask-http-methods/index.html",
    "title": "HTTP Methods in Flask",
    "section": "",
    "text": "The hypertext transfer protocol (HTTP) is a way for a web application to respond to requests.\nThere are four HTTP methods that you’ll typically find in introductory material:\n\nGET\nPOST\nPUT\nDELETE\n\nIn this post we’ll provide a simple example. We will embed the following video\n\n\nwhen GET is used. If the method is POST, then the page will render \"POST\". Otheriwse the function implicitly returns None, which offhand I don’t think does much of anything.\nimport getpass\n\nfrom flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route('/automorphisms', methods=['GET', 'POST'])\ndef http_methods_example():\n    if request.method == 'GET':\n        return '&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vY1UkCPSKH8?si=mRB5eM30UmTUVfhv\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen&gt;&lt;/iframe&gt;'\n    if request.method == 'POST':\n        return 'POST'\n    # We don't need to bother with PUT and DELETE\n\nif __name__ == '__main__':\n    app.run(debug=True)\nOther than taking the parameter methods in app.route, there isn’t much to this application. We’re showing a tag for an embedded video, which for us to render only involves returning a string of the tag."
  },
  {
    "objectID": "posts/python-clie-log-trace/index.html",
    "href": "posts/python-clie-log-trace/index.html",
    "title": "A Python CLI Example to Log the Execution Trace",
    "section": "",
    "text": "This is just a short script implementing a logger of the trace of a Python program’s execution.\nimport datetime\nfrom typing import Optional, Callable, Any, Tuple\nimport sys\n\nimport click\n\ndef trace_function(frame: Any, event: str, arg: Any) -&gt; Optional[Callable]:\n    \"\"\"\n    Trace function for monitoring function calls.\n\n    Args:\n        frame (frame): The current frame being executed.\n        event (str): The event type triggering the trace function.\n        arg (Any): The argument associated with the event.\n\n    Returns:\n        Optional[Callable]: The trace function or None to stop tracing.\n    \"\"\"\n    if not hasattr(trace_function, 'log_initialized'):\n        # Initialize log file with column titles if not already done\n        with open('trace_log.txt', 'w') as log_file:\n            log_file.write(\"Timestamp | Event | Function | File | Line | Argument\\n\")\n        trace_function.log_initialized = True\n\n    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    file_name = frame.f_globals.get('__file__', 'unknown')\n    log_entry = f\"{current_time} | {event} | {frame.f_code.co_name} | {file_name} | {frame.f_lineno} | {arg}\\n\"\n    with open('trace_log.txt', 'a') as log_file:\n        log_file.write(log_entry)\n    return trace_function\n\n@click.command()\n@click.argument('target_script', type=click.Path(exists=True))\ndef trace(target_script: str) -&gt; None:\n    \"\"\"\n    Trace function to monitor the execution of a target script.\n\n    Args:\n        target_script (str): Path to the target script to be traced.\n\n    Returns:\n        None\n    \"\"\"\n    # Set the trace function\n    sys.settrace(trace_function)\n\n    # Run the target script\n    with open(target_script, 'r') as script_file:\n        exec(script_file.read(), {})\n\n    # Disable the trace function\n    sys.settrace(None)\n\nif __name__ == '__main__':\n    trace()\nUsing it is straightforward:\n$ Python trace_util.py you_python_script.py"
  },
  {
    "objectID": "posts/automorphism-orbits-of-graphlets/index.html",
    "href": "posts/automorphism-orbits-of-graphlets/index.html",
    "title": "Automorphism Orbits of Graphlets",
    "section": "",
    "text": "Back in May 2020 I released a video on YouTube for the HackSeq event:\n\n\nBut I figure I could give some written description as well, which is what the rest of this blog post covers.\nA graph is a 2-tuple containing a set of edges and a set of vertices, and the set of edges is a subset of the cartesian product of the set of vertices with itself. We can think the vertices as ‘things’ and the set of edges as a binary relation between them.\nSometimes graphs are called “networks” when either the vertices (often called “nodes” when discussing networks) or edges have additional attributes, however this usage is not universally accepted. Three common properties of graph edges are whether they are directed, signed, or weighted. In the case of directed edges, some sort of ‘directionality’ is associated with the edges, and we’d say that (u,v) and (v,u) are considered distinct for two vertices u and v from the graph. A graph with directed edges is called a directed graph or a digraph. In the case of signed edges, each edge is assigned a ‘positive’ or ‘negative’ value, and we call such a graph a signed graph. In the case of weighted edges, each edge is assigned a numerical value, and we call such a graph a weighted graph. If a graph doesn’t have directed, signed, or weighted edges and doesn’t have multiple edges for any given pair of vertices, then it is called a simple graph.\nA graphlet is a specific type of graph, inheriting all the properties of graphs but also being a weakly-connected induced subgraph. For a graph to be subgraph, there exists another graph such that the subgraph’s vertex set is a subset of the other graph’s vertex set and the subgraph’s edge set is a subset of the other graph’s edge set. A subgraph being induced can be thought of procedurally, by first selecting any subset of the vertices and then also selecting all edges that connect those selected vertices. The property of weakly-connected can be considered for any graph, and means that there exists a path between any pair of vertices in the graph.\nA function is injective if it satisfies that f(x)=f(y) implies that x=y.\n\n\n\nhttps://mathworld.wolfram.com/images/eps-gif/Injection_1000.gif\n\n\nA function is surjective if it satisfies for any element b in the image that there exists an element a of the domain for which b=f(a).\n\n\n\nhttps://mathworld.wolfram.com/images/eps-gif/Surjection_1000.gif\n\n\nA bijection is a function that is both injective (one-to-one) and surjective (onto) from one set to another (these two sets can be the same set).\n\n\n\nhttps://mathworld.wolfram.com/images/eps-gif/Bijection_1000.gif\n\n\nA graph isomorphism is a bijection f between two graphs (which can be the same graph in the case of graph automorphisms) such that any two vertices u and v in the first graph are adjacent if-and-only-if f(u) and f(v) are adjacent.\n\n\n\nhttps://upload.wikimedia.org/wikipedia/commons/9/9a/Graph_isomorphism_a.svg\n\n\n\n\n\nhttps://upload.wikimedia.org/wikipedia/commons/8/84/Graph_isomorphism_b.svg\n\n\nA graph automorphism is a graph isomorphism where the domain graph and the image graph are the same graph.\n\n\n\nhttps://mathworld.wolfram.com/images/eps-gif/GraphAutomorphismGridGraph_1000.gif\n\n\nAn equivalence relation is a binary relation that is reflexive, symmetric, and transitive. An equivalence class is a subset of a set such that all members of the subset adhere to an equivalence relation. A (vertex) orbit automorphism is an equivalence class from the vertex set of a graph under the action of a graph automorphism. Multiple graph automorphisms are possible, and the set of all automorphisms with composition of permutations of the vertex set is called a permutation group.\nSince graphlets are graphs, and orbit automorphisms can be found within graphs, we can find orbit automorphisms within graphlets. The idea behind enumeration of orbit automorphisms of graphlets is to count the number of times each vertex of a graph participates in each orbit automorphism of each graphlet from a set of graphlets. While each finite graph has a finite number of distinct (i.e. mutually non-isomorphic) graphlets, considering every conceivable graphlet would be computationally infeasible. Instead of considering all graphlets of a graph, a constraint is often imposed where graphlets containing only 2-3 vertices are considered.\nEnumeration of orbit automorphisms of graphlets has been used to characterize correlation networks of coexpression of genes, and characterize the role of traders in the world trade network."
  },
  {
    "objectID": "posts/flask-url-for/index.html",
    "href": "posts/flask-url-for/index.html",
    "title": "Creating URL using url_for in Flask",
    "section": "",
    "text": "In this post I quickly show how the url_for command allows us to generate URLs. It isn’t a fundamental feature, but it can save you some boilerplate.\nimport requests\nimport io\n\nfrom flask import Flask, url_for\n\napp = Flask(__name__)\n\n@app.route('/card/&lt;int:card_id&gt;')\ndef card(card_id):\n    return f'Card({card_id})'\n\nwith app.test_request_context():\n    for i in range(10):\n        print(url_for('card', card_id=str(i)))\n\nif __name__ == '__main__':\n    app.run(debug=True)\nThe function test_request_context is described in its API documentation as follows:\n\nCreate a RequestContext for a WSGI environment created from the given values. This is mostly useful during testing, where you may want to run a function that uses request data without dispatching a full request.\n\nIndeed, if you look at the CLI output from running the application you will see something like this:\n/card/0\n/card/1\n/card/2\n/card/3\n/card/4\n/card/5\n/card/6\n/card/7\n/card/8\n/card/9\nWhile this is a simple example. you can use url_for to create more complicated URLs and content."
  },
  {
    "objectID": "posts/unzip-inaturalist-observations-ubuntu/index.html",
    "href": "posts/unzip-inaturalist-observations-ubuntu/index.html",
    "title": "Unzip Your iNaturalist Observations On A Ubuntu System",
    "section": "",
    "text": "Note\n\n\n\nThis post was migrated from my iNaturalist journal to my Jekyll blog on 2023-02-26. It was then migrated to my Quarto blog on 2024-07-27.\n\n\nSuppose - you have just downloaded an export of iNaturalist data, - the data file is a zipped comma-separated value(CSV) text file, - and you are running a Ubuntu system.\nBegin by opening up a BASH environment.\nGo to the path where the file was downloaded to:\ncd /path/to/folder\nThen run the unzip command:\nunzip observations-&lt;ID&gt;.csv.zip\nYou should find that you now have the uncompressed CSV file. You can check with:\nls observations-&lt;ID&gt;.csv"
  },
  {
    "objectID": "posts/combining-kedro-with-rye/index.html",
    "href": "posts/combining-kedro-with-rye/index.html",
    "title": "Combining Kedro with Rye",
    "section": "",
    "text": "I recently asked on the Kedro Slack channel about what experience people have had with combining Kedro with package management tools in Python such as PDM, Poetry, Hatch or Rye. juanlu gave a couple of options. You can either initialize a Kedro project first and then add the package manager, or add the package manager first and use kedro-init to fill in a Kedro project. Which one is more appropriate will depend on what already exists in your project. Kedro should be compatible with PEP-compliant packages (see discussion here) and also Poetry. I’m not sure about Rye.\nkedro-init is in its infancy (e.g. still needing documentation), but I figured I would try it out with Rye since that is what I am currently using on my personal machine."
  },
  {
    "objectID": "posts/combining-kedro-with-rye/index.html#introduction",
    "href": "posts/combining-kedro-with-rye/index.html#introduction",
    "title": "Combining Kedro with Rye",
    "section": "",
    "text": "I recently asked on the Kedro Slack channel about what experience people have had with combining Kedro with package management tools in Python such as PDM, Poetry, Hatch or Rye. juanlu gave a couple of options. You can either initialize a Kedro project first and then add the package manager, or add the package manager first and use kedro-init to fill in a Kedro project. Which one is more appropriate will depend on what already exists in your project. Kedro should be compatible with PEP-compliant packages (see discussion here) and also Poetry. I’m not sure about Rye.\nkedro-init is in its infancy (e.g. still needing documentation), but I figured I would try it out with Rye since that is what I am currently using on my personal machine."
  },
  {
    "objectID": "posts/combining-kedro-with-rye/index.html#example",
    "href": "posts/combining-kedro-with-rye/index.html#example",
    "title": "Combining Kedro with Rye",
    "section": "Example",
    "text": "Example\nFirst, lets initialize a Rye-managed project called try-kedro-init.\n$ rye init try-kedro-init\nsuccess: Initialized project in /home/galen/projects/try-kedro-init\n  Run `rye sync` to get started\nNow change directory into the project path.\n$ cd try-kedro-init/\nAdd the kedro-init package to try-kedro-init’s packages, inlcuding Kedro itself.\n$ rye add kedro-init\nInitializing new virtualenv in /home/galen/projects/try-kedro-init/.venv\nPython version: cpython@3.12.3\nAdded kedro-init&gt;=0.1.0 as regular dependency\nReusing already existing virtualenv\nGenerating production lockfile: /home/galen/projects/try-kedro-init/requirements.lock\nGenerating dev lockfile: /home/galen/projects/try-kedro-init/requirements-dev.lock\nInstalling dependencies\nResolved 55 packages in 12ms\n   Built try-kedro-init @ file:///home/galen/projects/try-kedro-init\n   Built antlr4-python3-runtime==4.9.3\nDownloaded 35 packages in 3.23s\nInstalled 55 packages in 16ms\n + antlr4-python3-runtime==4.9.3\n + arrow==1.3.0\n + attrs==23.2.0\n + binaryornot==0.4.4\n + build==1.2.1\n + cachetools==5.3.3\n + certifi==2024.6.2\n + chardet==5.2.0\n + charset-normalizer==3.3.2\n + click==8.1.7\n + cookiecutter==2.6.0\n + dynaconf==3.2.5\n + fastjsonschema==2.20.0\n + fsspec==2024.6.1\n + gitdb==4.0.11\n + gitpython==3.1.43\n + idna==3.7\n + importlib-metadata==7.2.1\n + importlib-resources==6.4.0\n + installer==0.7.0\n + jinja2==3.1.4\n + kedro==0.19.6\n + kedro-init==0.1.0\n + markdown-it-py==3.0.0\n + markupsafe==2.1.5\n + mdurl==0.1.2\n + more-itertools==10.3.0\n + omegaconf==2.3.0\n + packaging==24.1\n + parse==1.20.2\n + platformdirs==4.2.2\n + pluggy==1.5.0\n + pre-commit-hooks==4.6.0\n + pygetimportables==0.2.1\n + pygments==2.18.0\n + pyproject-hooks==1.1.0\n + python-dateutil==2.9.0.post0\n + python-slugify==8.0.4\n + pytoolconfig==1.3.1\n + pyyaml==6.0.1\n + requests==2.32.3\n + rich==13.7.1\n + rope==1.13.0\n + ruamel-yaml==0.18.6\n + ruamel-yaml-clib==0.2.8\n + six==1.16.0\n + smmap==5.0.1\n + text-unidecode==1.3\n + toml==0.10.2\n + tomlkit==0.12.5\n + try-kedro-init==0.1.0 (from file:///home/galen/projects/try-kedro-init)\n + types-python-dateutil==2.9.0.20240316\n + urllib3==2.2.2\n + validate-pyproject==0.18\n + zipp==3.19.2\nDone!\nNow run kedro-init from within Rye’s virtual environment.\n$ rye run kedro-init .\n[08:33:20] Looking for existing package directories                                                                                                                                                                                cli.py:25\n[08:33:25] Initialising config directories                                                                                                                                                                                         cli.py:25\n           Creating modules                                                                                                                                                                                                        cli.py:25\n           🔶 Kedro project successfully initialised!\nJust for the sake of example, create an example pipeline.\n$ rye run kedro pipeline create example_pipeline\nUsing pipeline template at: '/home/galen/projects/try-kedro-init/.venv/lib/python3.12/site-packages/kedro/templates/pipeline'\nCreating the pipeline 'example_pipeline': OK\n  Location: '/home/galen/projects/try-kedro-init/src/try_kedro_init/pipelines/example_pipeline'\nCreating '/home/galen/projects/try-kedro-init/tests/pipelines/example_pipeline/test_pipeline.py': OK\nCreating '/home/galen/projects/try-kedro-init/tests/pipelines/example_pipeline/__init__.py': OK\nCreating '/home/galen/projects/try-kedro-init/conf/base/parameters_example_pipeline.yml': OK\n\nPipeline 'example_pipeline' was successfully created.\nNow take a look at the path tree to see what has been created.\n$ tree .\n.\n├── conf\n│   ├── base\n│   │   └── parameters_example_pipeline.yml\n│   └── local\n├── pyproject.toml\n├── README.md\n├── requirements-dev.lock\n├── requirements.lock\n├── src\n│   └── try_kedro_init\n│       ├── __init__.py\n│       ├── pipeline_registry.py\n│       ├── pipelines\n│       │   └── example_pipeline\n│       │       ├── __init__.py\n│       │       ├── nodes.py\n│       │       └── pipeline.py\n│       ├── __pycache__\n│       │   ├── __init__.cpython-312.pyc\n│       │   └── settings.cpython-312.pyc\n│       └── settings.py\n└── tests\n    └── pipelines\n        └── example_pipeline\n            ├── __init__.py\n            └── test_pipeline.py\n\n11 directories, 15 files\nThe catalog.yml and parameters.yml files were not made by default, but they are just plaintext files that can be readily added. There is parameters_example_pipeline.yml for the pipeline we just created.\n$ touch conf/base/catalog.yml\nThere also is not a data path by default, which should exist at the root of the project. We can also add that.\n $ mkdir data\nLet us create an example CSV dataset at data/example_data.csv with the following contents:\nID,Name,Age,Email\n1,John Doe,28,john.doe@example.com\n2,Jane Smith,34,jane.smith@example.com\n3,Bob Johnson,45,bob.johnson@example.com\n4,Alice Williams,23,alice.williams@example.com\n5,Michael Brown,37,michael.brown@example.com\nThen add an entry to conf/base/catalog.yml:\nexample_dataset:\n  type: pandas.CSVDataset\n  filepath: ./data/example_data.csv\n  load_args:\n    sep: \",\"\nNow update src/try_kedro_init/pipelines/example_pipeline/pipeline.py from this\n\"\"\"\nThis is a boilerplate pipeline 'example_pipeline'\ngenerated using Kedro 0.19.6\n\"\"\"\n\nfrom kedro.pipeline import Pipeline, pipeline\n\n\ndef create_pipeline(**kwargs) -&gt; Pipeline:\n    return pipeline([])\nto this:\n\"\"\"\nThis is a boilerplate pipeline 'example_pipeline'\ngenerated using Kedro 0.19.6\n\"\"\"\n\nfrom kedro.pipeline import Pipeline, pipeline, node\n\n\ndef create_pipeline(**kwargs) -&gt; Pipeline:\n    return pipeline([\n        node(\n            func=print,\n            inputs=['example_dataset'],\n            outputs=None\n            )\n        ])\nNow install kedro-datasets and pandas:\n$ rye add kedro-datasets pandas\nAdded kedro-datasets&gt;=3.0.1 as regular dependency\nAdded pandas&gt;=2.2.2 as regular dependency\nReusing already existing virtualenv\nGenerating production lockfile: /home/galen/projects/try-kedro-init/requirements.lock\nGenerating dev lockfile: /home/galen/projects/try-kedro-init/requirements-dev.lock\nInstalling dependencies\nResolved 61 packages in 14ms\n   Built try-kedro-init @ file:///home/galen/projects/try-kedro-init\nDownloaded 1 package in 217ms\nUninstalled 1 package in 0.29ms\nInstalled 5 packages in 45ms\n + numpy==2.0.0\n + pandas==2.2.2\n + pytz==2024.1\n - try-kedro-init==0.1.0 (from file:///home/galen/projects/try-kedro-init)\n + try-kedro-init==0.1.0 (from file:///home/galen/projects/try-kedro-init)\n + tzdata==2024.1\nDone!\nFinally, run the Kedro pipeline:\n$ rye run kedro run\n[07/01/24 09:18:48] INFO     Kedro project try-kedro-init                                                                                                                                                                     session.py:324\n[07/01/24 09:18:49] INFO     Using synchronous mode for loading and saving data. Use the --async flag for potential performance gains.                                                                               sequential_runner.py:64\n                             https://docs.kedro.org/en/stable/nodes_and_pipelines/run_a_pipeline.html#load-and-save-asynchronously                                                                                                          \n                    INFO     Loading data from example_dataset (CSVDataset)...                                                                                                                                           data_catalog.py:508\n                    INFO     Running node: print([example_dataset]) -&gt; None                                                                                                                                                      node.py:361\n   ID            Name  Age                       Email\n0   1        John Doe   28        john.doe@example.com\n1   2      Jane Smith   34      jane.smith@example.com\n2   3     Bob Johnson   45     bob.johnson@example.com\n3   4  Alice Williams   23  alice.williams@example.com\n4   5   Michael Brown   37   michael.brown@example.com\n                    INFO     Completed 1 out of 1 tasks                                                                                                                                                              sequential_runner.py:90\n                    INFO     Pipeline execution completed successfully.                                                                                                                                                        runner.py:119\nMy provisional conclusion is that Kedro and Rye are compatible."
  },
  {
    "objectID": "posts/combining-kedro-with-rye/index.html#versions",
    "href": "posts/combining-kedro-with-rye/index.html#versions",
    "title": "Combining Kedro with Rye",
    "section": "Versions",
    "text": "Versions\nRye configuration:\n$ rye --version\nrye 0.35.0\ncommit: 0.35.0 (a1dbc56d4 2024-06-24)\nplatform: linux (x86_64)\nself-python: cpython@3.12.3\nsymlink support: true\nuv enabled: true\nMy operating system:\n$ lsb_release -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 22.04.4 LTS\nRelease:        22.04\nCodename:       jammy"
  },
  {
    "objectID": "posts/rust-run-from-python/index.html",
    "href": "posts/rust-run-from-python/index.html",
    "title": "Build and Run a Rust Project from Quarto Using Python",
    "section": "",
    "text": "In a previous post I used a Lua extension to compile a Rust file using the rustc compiler. I ran into multiple problems.\nUsing rustc rather than Cargo means that I miss out on a lot of the build tools, and it is also less conventional for Rust projects.\nThere were also issues with my plugin. It did not correctly turn off echo either locally to a code block, or to the global setting in the preamble of the Quarto file. It also did not put code on a new line. Further, I got feedback that this might not be supported. I also learned from a discussion answer on the Quarto Github discussion board that there are tools that might be better.\nWhile other tools like evcxr look appealing, I have not looked into how to exactly integrate it with Quarto yet.\nBut there is a low-hanging fruit we can take advantage of here. We can certainly use Python subprocess library to indirectly orchestrate building and running a rust project. It also allows us to capture the output as text and return that into a Jupyter notebook. So that’s exaxtly what I made:\nimport subprocess\nimport os\nimport stat\n\ndef log_permissions(path):\n    st = os.stat(path)\n    permissions = stat.filemode(st.st_mode)\n    print(f\"Permissions for {path}: {permissions}\")\n\ndef compile_and_run_rust(target_file):\n    # Get the directory and the file name\n    target_dir = os.path.dirname(target_file)\n    target_name = os.path.basename(target_dir)  # Adjusted to get the correct target name\n\n    # Ensure Cargo.toml exists in the target directory\n    cargo_toml_path = os.path.join(target_dir, 'Cargo.toml')\n    if not os.path.exists(cargo_toml_path):\n        raise FileNotFoundError(\"Cargo.toml not found in the target directory.\")\n\n    # Compile the Rust project\n    try:\n        build_process = subprocess.run(\n            ['cargo', 'build', '--release'],\n            cwd=target_dir,\n            check=True,\n            capture_output=True,\n            text=True\n        )\n    except subprocess.CalledProcessError as e:\n        print(f\"Compilation Error: {e.stderr}\")\n        return\n\n    # Find the compiled executable\n    target_exe = os.path.join(target_dir, 'target', 'release', target_name)\n    if os.name == 'nt':\n        target_exe += '.exe'\n\n    if not os.path.exists(target_exe):\n        raise FileNotFoundError(\"Compiled executable not found.\")\n\n    if os.name != 'nt':\n        try:\n            os.chmod(target_exe, stat.S_IRWXU | stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)\n            os.chmod(os.path.dirname(target_exe), stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n        except PermissionError as e:\n            print(f\"Error setting permissions: {e}\")\n            return\n\n    # Run the compiled executable and capture its output\n    try:\n        run_process = subprocess.run(\n            [target_exe],\n            check=True,\n            capture_output=True,\n            text=True\n        )\n        output = run_process.stdout\n        return output\n    except subprocess.CalledProcessError as e:\n        print(f\"Execution Error: {e.stderr}\")\n        return\n\n# Example usage\nif __name__ == \"__main__\":\n    output = compile_and_run_rust('../posts/rust-run-from-python/hello/main.rs')\n    print(output)\nPython Jupyter notebooks run Python in interactive mode, so it is slightly less convenient for importing Python files. Nonetheless this can be done by inserting our script into the path using the sys library. Once we have imported the run_rust file, we can call the compile_and_run_rust pointing to a Rust project path that is locally stored\nLet us start a Rust project called “hello”.\ncargo init hello\nI also added a loop with a println macro just so we can see how this approach handles keeping newline characters. Here is the Rust code in hello/src/main.rs.\nfn main() {\n\n    let mut count = 0;\n\n    loop {\n        count = count + 1;\n        println!(\"{} Hello, world!\", count);\n        if count &gt; 11 {\n            break\n        }\n    }\n}\nThe above Rust code should print a series of lines each starting with a number, with the numbers ranging from 1 to 12.\nWith all that setup, we can now try using the run_rust.compile_and_run_rust process caller.\n\nimport sys\nsys.path.insert(1, '../../scripts')\n\nimport run_rust\n\nprint(run_rust.compile_and_run_rust('./hello/'))\n\n1 Hello, world!\n2 Hello, world!\n3 Hello, world!\n4 Hello, world!\n5 Hello, world!\n6 Hello, world!\n7 Hello, world!\n8 Hello, world!\n9 Hello, world!\n10 Hello, world!\n11 Hello, world!\n12 Hello, world!\n\n\n\nAnd there we have it! We can further try again, but with #| echo: false in the Python code block to turn off echo:\n\n\n1 Hello, world!\n2 Hello, world!\n3 Hello, world!\n4 Hello, world!\n5 Hello, world!\n6 Hello, world!\n7 Hello, world!\n8 Hello, world!\n9 Hello, world!\n10 Hello, world!\n11 Hello, world!\n12 Hello, world!\n\n\n\nIn conclusion, this approach using Python itself and Python Jupyter notebooks to compile, run, and display the printed output from a Rust program. It succeeds in preserving newline characters, and echo works locally. It also works globally for the whole file. The only remaining thing to watch out for in particular if Quarto’s automatic freezing of posts will not detect if you have changed the Rust code; you may need to change your qmd file in some way."
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "Integrating Causal Inference Methods into Northern Health’s Analytics Work\n\n\nObjective: This talk aims to highlight the integration of modern causal inference methods into the decision-making processes at Northern Health (NH). I present a comprehensive approach to incorporate causal inference principles into NH’s analytics work, emphasizing the significance of causality in healthcare research and its alignment with NH’s mission, vision, and strategic plans.\nMethods: The presentation outlines our approach, which involves the development of a systematic causal model development process. These methods are designed to equip NH’s data scientists and researchers with the skills necessary to apply modern causal inference techniques effectively.\nResults: I discuss the theoretical foundations and the framework for integrating modern causal inference methodologies into NH’s projects. I highlight the general challenges and benefits of applying causal inference methods in healthcare research, including addressing incomplete or corrupted data, accounting for unmeasured confounds, and estimating heterogeneous treatment effects at the individual level. Finally, I will report on the current state of a project to estimate the causal impact of COVID-19 on a time series data set in NH.\nLessons Learned: Causality has deep roots in philosophy, and modern causal inference offers a rigorous framework to address the complexities of healthcare data analysis. I emphasize the critical distinction between causal inference and traditional statistics and demonstrate how misleading statistics can misguide decision-making. I stress that causal inference methodologies are in harmony with NH’s mission, vision, and strategic objectives, enhancing the quality of inferences drawn from healthcare data.\n\n\nA Friendly Introduction to Statistical Forecasting\nA Moosy Proposal: Estimating Average Direction of Moose Travel from Weak Information\nAdventures in Non-Negative Canonical Polyadic Decomposition\nHow Correlation Really Works\nIntroduction to Interval Arithmetic\nIntroduction to Using ARIMA\nExample of Training a SARIMAX Model\nReview of a Study Using SARIMAX Guest lecture: Relations and Graphs\nA Gentle Introduction to Geometric Deep Learning{:target=“_blank”}\n\n\n\n\nPractical Approaches to Faster and Leaner Python{:target=“_blank”}\n\n\n\n\nA Gentle Introduction to L-Systems{:target=“_blank”}\nEnumeration of Automorphism Orbits of Graphlets (HackSeq){:target=“_blank”}"
  }
]