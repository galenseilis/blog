[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Galen Seilis",
    "section": "",
    "text": "Galen is a science and technology enthusiast dedicated to life-long learning. Through the application of ethics, reason, and observation, he believes we can tackle problems in medicine, the environment, economics, and exploration."
  },
  {
    "objectID": "posts/how-to-compile-python-on-linux/index.html",
    "href": "posts/how-to-compile-python-on-linux/index.html",
    "title": "How to Compile CPython on Debian-Based Linux",
    "section": "",
    "text": "This is a short blog post to remind myself how to compile CPython from its source.\nYou need to get the source files for Python as you need to give the C compiler (and other tools) the needed instructions for producing machine code. These CPython source is available on Github. Using git, you can download with\n$ git clone https://github.com/python/cpython.git\nYou should install build-essential which provides tooling for building Debian packages. This can be done with apt:\n$ sudo apt install build-essential\nNext install these assorted packages:\n$ sudo apt install libssl-dev zlib1g-dev libncurses5-dev libncursesw5-dev libreadline-dev libsqlite3-dev libgdbm-dev libdb5.3-dev libbz2-dev liblzma-dev libffi-dev\nNow run the configuration tool that the Python dev’s have kindly prepared. It will prepare a makefile for everything you need to build CPython.\n$ ./configure --with-pydebug\nFinally, you can just run make.\n$ make\nThat’s pretty much it. If you want to silence the large standard output, you can add an -s. By default make will compile the first target specified in the make file, which for this project is actually the entirety of CPython itself. You can specify special build targets related to building, testing, installation, and other topics."
  },
  {
    "objectID": "posts/combining-kedro-with-rye/index.html",
    "href": "posts/combining-kedro-with-rye/index.html",
    "title": "Combining Kedro with Rye",
    "section": "",
    "text": "I recently asked on the Kedro Slack channel about what experience people have had with combining Kedro with package management tools in Python such as PDM, Poetry, Hatch or Rye. juanlu gave a couple of options. You can either initialize a Kedro project first and then add the package manager, or add the package manager first and use kedro-init to fill in a Kedro project. Which one is more appropriate will depend on what already exists in your project. Kedro should be compatible with PEP-compliant packages (see discussion here) and also Poetry. I’m not sure about Rye.\nkedro-init is in its infancy (e.g. still needing documentation), but I figured I would try it out with Rye since that is what I am currently using on my personal machine."
  },
  {
    "objectID": "posts/combining-kedro-with-rye/index.html#introduction",
    "href": "posts/combining-kedro-with-rye/index.html#introduction",
    "title": "Combining Kedro with Rye",
    "section": "",
    "text": "I recently asked on the Kedro Slack channel about what experience people have had with combining Kedro with package management tools in Python such as PDM, Poetry, Hatch or Rye. juanlu gave a couple of options. You can either initialize a Kedro project first and then add the package manager, or add the package manager first and use kedro-init to fill in a Kedro project. Which one is more appropriate will depend on what already exists in your project. Kedro should be compatible with PEP-compliant packages (see discussion here) and also Poetry. I’m not sure about Rye.\nkedro-init is in its infancy (e.g. still needing documentation), but I figured I would try it out with Rye since that is what I am currently using on my personal machine."
  },
  {
    "objectID": "posts/combining-kedro-with-rye/index.html#example",
    "href": "posts/combining-kedro-with-rye/index.html#example",
    "title": "Combining Kedro with Rye",
    "section": "Example",
    "text": "Example\nFirst, lets initialize a Rye-managed project called try-kedro-init.\n$ rye init try-kedro-init\nsuccess: Initialized project in /home/galen/projects/try-kedro-init\n  Run `rye sync` to get started\nNow change directory into the project path.\n$ cd try-kedro-init/\nAdd the kedro-init package to try-kedro-init’s packages, inlcuding Kedro itself.\n$ rye add kedro-init\nInitializing new virtualenv in /home/galen/projects/try-kedro-init/.venv\nPython version: cpython@3.12.3\nAdded kedro-init&gt;=0.1.0 as regular dependency\nReusing already existing virtualenv\nGenerating production lockfile: /home/galen/projects/try-kedro-init/requirements.lock\nGenerating dev lockfile: /home/galen/projects/try-kedro-init/requirements-dev.lock\nInstalling dependencies\nResolved 55 packages in 12ms\n   Built try-kedro-init @ file:///home/galen/projects/try-kedro-init\n   Built antlr4-python3-runtime==4.9.3\nDownloaded 35 packages in 3.23s\nInstalled 55 packages in 16ms\n + antlr4-python3-runtime==4.9.3\n + arrow==1.3.0\n + attrs==23.2.0\n + binaryornot==0.4.4\n + build==1.2.1\n + cachetools==5.3.3\n + certifi==2024.6.2\n + chardet==5.2.0\n + charset-normalizer==3.3.2\n + click==8.1.7\n + cookiecutter==2.6.0\n + dynaconf==3.2.5\n + fastjsonschema==2.20.0\n + fsspec==2024.6.1\n + gitdb==4.0.11\n + gitpython==3.1.43\n + idna==3.7\n + importlib-metadata==7.2.1\n + importlib-resources==6.4.0\n + installer==0.7.0\n + jinja2==3.1.4\n + kedro==0.19.6\n + kedro-init==0.1.0\n + markdown-it-py==3.0.0\n + markupsafe==2.1.5\n + mdurl==0.1.2\n + more-itertools==10.3.0\n + omegaconf==2.3.0\n + packaging==24.1\n + parse==1.20.2\n + platformdirs==4.2.2\n + pluggy==1.5.0\n + pre-commit-hooks==4.6.0\n + pygetimportables==0.2.1\n + pygments==2.18.0\n + pyproject-hooks==1.1.0\n + python-dateutil==2.9.0.post0\n + python-slugify==8.0.4\n + pytoolconfig==1.3.1\n + pyyaml==6.0.1\n + requests==2.32.3\n + rich==13.7.1\n + rope==1.13.0\n + ruamel-yaml==0.18.6\n + ruamel-yaml-clib==0.2.8\n + six==1.16.0\n + smmap==5.0.1\n + text-unidecode==1.3\n + toml==0.10.2\n + tomlkit==0.12.5\n + try-kedro-init==0.1.0 (from file:///home/galen/projects/try-kedro-init)\n + types-python-dateutil==2.9.0.20240316\n + urllib3==2.2.2\n + validate-pyproject==0.18\n + zipp==3.19.2\nDone!\nNow run kedro-init from within Rye’s virtual environment.\n$ rye run kedro-init .\n[08:33:20] Looking for existing package directories                                                                                                                                                                                cli.py:25\n[08:33:25] Initialising config directories                                                                                                                                                                                         cli.py:25\n           Creating modules                                                                                                                                                                                                        cli.py:25\n           🔶 Kedro project successfully initialised!\nJust for the sake of example, create an example pipeline.\n$ rye run kedro pipeline create example_pipeline\nUsing pipeline template at: '/home/galen/projects/try-kedro-init/.venv/lib/python3.12/site-packages/kedro/templates/pipeline'\nCreating the pipeline 'example_pipeline': OK\n  Location: '/home/galen/projects/try-kedro-init/src/try_kedro_init/pipelines/example_pipeline'\nCreating '/home/galen/projects/try-kedro-init/tests/pipelines/example_pipeline/test_pipeline.py': OK\nCreating '/home/galen/projects/try-kedro-init/tests/pipelines/example_pipeline/__init__.py': OK\nCreating '/home/galen/projects/try-kedro-init/conf/base/parameters_example_pipeline.yml': OK\n\nPipeline 'example_pipeline' was successfully created.\nNow take a look at the path tree to see what has been created.\n$ tree .\n.\n├── conf\n│   ├── base\n│   │   └── parameters_example_pipeline.yml\n│   └── local\n├── pyproject.toml\n├── README.md\n├── requirements-dev.lock\n├── requirements.lock\n├── src\n│   └── try_kedro_init\n│       ├── __init__.py\n│       ├── pipeline_registry.py\n│       ├── pipelines\n│       │   └── example_pipeline\n│       │       ├── __init__.py\n│       │       ├── nodes.py\n│       │       └── pipeline.py\n│       ├── __pycache__\n│       │   ├── __init__.cpython-312.pyc\n│       │   └── settings.cpython-312.pyc\n│       └── settings.py\n└── tests\n    └── pipelines\n        └── example_pipeline\n            ├── __init__.py\n            └── test_pipeline.py\n\n11 directories, 15 files\nThe catalog.yml and parameters.yml files were not made by default, but they are just plaintext files that can be readily added. There is parameters_example_pipeline.yml for the pipeline we just created.\n$ touch conf/base/catalog.yml\nThere also is not a data path by default, which should exist at the root of the project. We can also add that.\n $ mkdir data\nLet us create an example CSV dataset at data/example_data.csv with the following contents:\nID,Name,Age,Email\n1,John Doe,28,john.doe@example.com\n2,Jane Smith,34,jane.smith@example.com\n3,Bob Johnson,45,bob.johnson@example.com\n4,Alice Williams,23,alice.williams@example.com\n5,Michael Brown,37,michael.brown@example.com\nThen add an entry to conf/base/catalog.yml:\nexample_dataset:\n  type: pandas.CSVDataset\n  filepath: ./data/example_data.csv\n  load_args:\n    sep: \",\"\nNow update src/try_kedro_init/pipelines/example_pipeline/pipeline.py from this\n\"\"\"\nThis is a boilerplate pipeline 'example_pipeline'\ngenerated using Kedro 0.19.6\n\"\"\"\n\nfrom kedro.pipeline import Pipeline, pipeline\n\n\ndef create_pipeline(**kwargs) -&gt; Pipeline:\n    return pipeline([])\nto this:\n\"\"\"\nThis is a boilerplate pipeline 'example_pipeline'\ngenerated using Kedro 0.19.6\n\"\"\"\n\nfrom kedro.pipeline import Pipeline, pipeline, node\n\n\ndef create_pipeline(**kwargs) -&gt; Pipeline:\n    return pipeline([\n        node(\n            func=print,\n            inputs=['example_dataset'],\n            outputs=None\n            )\n        ])\nNow install kedro-datasets and pandas:\n$ rye add kedro-datasets pandas\nAdded kedro-datasets&gt;=3.0.1 as regular dependency\nAdded pandas&gt;=2.2.2 as regular dependency\nReusing already existing virtualenv\nGenerating production lockfile: /home/galen/projects/try-kedro-init/requirements.lock\nGenerating dev lockfile: /home/galen/projects/try-kedro-init/requirements-dev.lock\nInstalling dependencies\nResolved 61 packages in 14ms\n   Built try-kedro-init @ file:///home/galen/projects/try-kedro-init\nDownloaded 1 package in 217ms\nUninstalled 1 package in 0.29ms\nInstalled 5 packages in 45ms\n + numpy==2.0.0\n + pandas==2.2.2\n + pytz==2024.1\n - try-kedro-init==0.1.0 (from file:///home/galen/projects/try-kedro-init)\n + try-kedro-init==0.1.0 (from file:///home/galen/projects/try-kedro-init)\n + tzdata==2024.1\nDone!\nFinally, run the Kedro pipeline:\n$ rye run kedro run\n[07/01/24 09:18:48] INFO     Kedro project try-kedro-init                                                                                                                                                                     session.py:324\n[07/01/24 09:18:49] INFO     Using synchronous mode for loading and saving data. Use the --async flag for potential performance gains.                                                                               sequential_runner.py:64\n                             https://docs.kedro.org/en/stable/nodes_and_pipelines/run_a_pipeline.html#load-and-save-asynchronously                                                                                                          \n                    INFO     Loading data from example_dataset (CSVDataset)...                                                                                                                                           data_catalog.py:508\n                    INFO     Running node: print([example_dataset]) -&gt; None                                                                                                                                                      node.py:361\n   ID            Name  Age                       Email\n0   1        John Doe   28        john.doe@example.com\n1   2      Jane Smith   34      jane.smith@example.com\n2   3     Bob Johnson   45     bob.johnson@example.com\n3   4  Alice Williams   23  alice.williams@example.com\n4   5   Michael Brown   37   michael.brown@example.com\n                    INFO     Completed 1 out of 1 tasks                                                                                                                                                              sequential_runner.py:90\n                    INFO     Pipeline execution completed successfully.                                                                                                                                                        runner.py:119\nMy provisional conclusion is that Kedro and Rye are compatible."
  },
  {
    "objectID": "posts/combining-kedro-with-rye/index.html#versions",
    "href": "posts/combining-kedro-with-rye/index.html#versions",
    "title": "Combining Kedro with Rye",
    "section": "Versions",
    "text": "Versions\nRye configuration:\n$ rye --version\nrye 0.35.0\ncommit: 0.35.0 (a1dbc56d4 2024-06-24)\nplatform: linux (x86_64)\nself-python: cpython@3.12.3\nsymlink support: true\nuv enabled: true\nMy operating system:\n$ lsb_release -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 22.04.4 LTS\nRelease:        22.04\nCodename:       jammy"
  },
  {
    "objectID": "posts/starting-data-science/index.html",
    "href": "posts/starting-data-science/index.html",
    "title": "Starting Data Science",
    "section": "",
    "text": "I’ve been thinking about Data Science lately, and I recently watched a YouTube video describing how to get started learning prerequisite knowledge for this field. While I am skeptical of the use of buzzwords, I think data science does reflect a loose collection of ideas and tools that are interesting and useful. Some of these subtopics include statistics, algorithms, databases, machine learning, and other miscellaneous topics within computer science and mathematics. I’m not partial to the term, but I am to the associated skillset.\nIn the interest of learning this subject in a structured way, I am going to go through the curricula suggested by Giles McMullen-Klein. I’ll modify it as it suites my needs or interests, but it serves as a simple template to get started with."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Seilis, Galen. The Importance of Partial Pooling with Northern Health Data. Research and Knowledge Translation Newsletter\n\n\nSeilis, Galen. Project: Advanced Analytics. Research and Knowledge Translation Newsletter."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "How to Compile CPython on Debian-Based Linux\n\n\n\n\n\n\nPython\n\n\nCPython\n\n\nC\n\n\ncompilation\n\n\nmake\n\n\nDebian\n\n\nLinux\n\n\n\n\n\n\n\n\n\nJul 25, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nMy Quarto Blog\n\n\n\n\n\n\nblog\n\n\nQuarto\n\n\nJekyll\n\n\nMermaid\n\n\nGraphviz\n\n\ndot\n\n\n\n\n\n\n\n\n\nJul 21, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nCombining Kedro with Rye\n\n\n\n\n\n\nKedro\n\n\nRye\n\n\n\n\n\n\n\n\n\nJul 1, 2024\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nQuantEcon 1 Scipy Submodules\n\n\n\n\n\n\nPython\n\n\nScipy\n\n\nNumPy\n\n\nscipy.optimize\n\n\nNewton Raphson method\n\n\nBrents method\n\n\ntimeit\n\n\nbisect method\n\n\noptimization\n\n\n\n\n\n\n\n\n\nMar 28, 2019\n\n\nGalen Seilis\n\n\n\n\n\n\n\n\n\n\n\n\nStarting Data Science\n\n\n\n\n\n\nData Science\n\n\n\n\n\n\n\n\n\nMar 23, 2019\n\n\nGalen Seilis\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/my-quarto-blog/index.html",
    "href": "posts/my-quarto-blog/index.html",
    "title": "My Quarto Blog",
    "section": "",
    "text": "I am switching to Quarto for my blog. My Jekyll blog is available here, and I might move some of the posts over to the new blog over time.\nCreating this blog was really easy. Was my Jekyll blog really complicated to setup? There were some technical hurdles around getting extra behaviour on my original blog, but overall it wasn’t extremely hard. Why am I switching to Quarto?\nWhat Quarto provides (that I want) is code execution followed by rendering the output of the code. I can put my code examples right into the blog post, and if something like a plot is produced then that plot will show on my blog.\nIn constrast, with Jekyll, I needed to\n\nmake the plot\nmove the plot to an images folder\nreference to the plot’s path in the blog post.\n\nIt wasn’t terrible, and it is possible that I just didn’t figure out how to make this easier with Jekyll, but it was quickly apparent to me that Quarto makes this easy.\nThis includes mermaid diagrams:\n\n\n\n\n\n---\ntitle: Example Git diagram\n---\ngitGraph\n   commit\n   commit\n   branch develop\n   checkout develop\n   commit\n   commit\n   checkout main\n   merge develop\n   commit\n   commit\n\n\n\n\n\n\nI can also easily prepare Graphiz diagrams provided that I supply some valid dot notation:\n\ndigraph finite_state_machine {\n    fontname=\"Helvetica,Arial,sans-serif\"\n    node [fontname=\"Helvetica,Arial,sans-serif\"]\n    edge [fontname=\"Helvetica,Arial,sans-serif\"]\n    rankdir=LR;\n    node [shape = doublecircle]; 0 3 4 8;\n    node [shape = circle];\n    0 -&gt; 2 [label = \"SS(B)\"];\n    0 -&gt; 1 [label = \"SS(S)\"];\n    1 -&gt; 3 [label = \"S($end)\"];\n    2 -&gt; 6 [label = \"SS(b)\"];\n    2 -&gt; 5 [label = \"SS(a)\"];\n    2 -&gt; 4 [label = \"S(A)\"];\n    5 -&gt; 7 [label = \"S(b)\"];\n    5 -&gt; 5 [label = \"S(a)\"];\n    6 -&gt; 6 [label = \"S(b)\"];\n    6 -&gt; 5 [label = \"S(a)\"];\n    7 -&gt; 8 [label = \"S(b)\"];\n    7 -&gt; 5 [label = \"S(a)\"];\n    8 -&gt; 6 [label = \"S(b)\"];\n    8 -&gt; 5 [label = \"S(a)\"];\n}\n\n\n\n\n\n\nfinite_state_machine\n\n\n\n0\n\n\n0\n\n\n\n2\n\n2\n\n\n\n0-&gt;2\n\n\nSS(B)\n\n\n\n1\n\n1\n\n\n\n0-&gt;1\n\n\nSS(S)\n\n\n\n3\n\n\n3\n\n\n\n4\n\n\n4\n\n\n\n8\n\n\n8\n\n\n\n6\n\n6\n\n\n\n8-&gt;6\n\n\nS(b)\n\n\n\n5\n\n5\n\n\n\n8-&gt;5\n\n\nS(a)\n\n\n\n2-&gt;4\n\n\nS(A)\n\n\n\n2-&gt;6\n\n\nSS(b)\n\n\n\n2-&gt;5\n\n\nSS(a)\n\n\n\n1-&gt;3\n\n\nS($end)\n\n\n\n6-&gt;6\n\n\nS(b)\n\n\n\n6-&gt;5\n\n\nS(a)\n\n\n\n5-&gt;5\n\n\nS(a)\n\n\n\n7\n\n7\n\n\n\n5-&gt;7\n\n\nS(b)\n\n\n\n7-&gt;8\n\n\nS(b)\n\n\n\n7-&gt;5\n\n\nS(a)\n\n\n\n\n\n\n\n\nThis is definitely desired behaviour."
  },
  {
    "objectID": "posts/quantecon-1-scipy-submodules/index.html",
    "href": "posts/quantecon-1-scipy-submodules/index.html",
    "title": "QuantEcon 1 Scipy Submodules",
    "section": "",
    "text": "As someone with previous background in Python, I’ve been blasting my way through the basics of the Quantecon curricula. One of the joys of self-directed learning is that, with discipline, you can speed through familar material and really camp out with the new material. With that in mind, I’ve decided to further play with finding solutions (x-intercepts) of some single variable functions.\nFirst of all, let’s find ourselves an interesting function. I’ve chosen \\(f(x) = \\sin(x) \\exp(-x)\\) because I’ve always enjoyed its degradating oscillations, but also because I expect this equation to have solutions. Since any integer multiple \\(k\\) of \\(\\pi\\) will result in \\(\\sin(x) = 0\\) when \\(x = k \\pi\\), we know that \\(f(k \\pi) = 0\\) as well. While I’m quite late (or too early, depending on how you see it) for calculating \\(\\pi\\) on \\(\\pi\\) Day, let’s take \\(k = 1\\) to find \\(\\pi\\) anyway!\n\nBisection Method\nThe first method mentioned on QuantEcon is the bisection algorithm, which essentially treats finding solutions to a function as a binary search problem. There are two parameters that are needed to get started with the bisection algorithm, an initial lower bound and an initial upper bound on the search space. Not only do we need two such parameters, but our choice of these two numbers can change what solution is found. Let’s consider the following example where we look on the interval \\([-10, 10]\\).\n\nimport numpy as np\nfrom scipy.optimize import bisect\n# Define a single-variable function to find solutions in\nf = lambda x: np.sin(x) * np.exp(-x)\n# try out the bisection algorithm\nprint(bisect(f, -10, 10))\n\n0.0\n\n\nWe were looking for \\(x = \\pi\\), but we got \\(x = 0\\) instead. If there are multiple solutions within your search interval, the algorithm won’t necessarily converge on the one that you wanted, nor will it report to you there were multiple solutions. Knowing ahead of time that we’d like to calculate \\(\\pi\\), and that \\(3 &lt; \\pi &lt; 4\\), let’s rerun the bisection algorithm on \\([3, 4]\\).\n\nprint(bisect(f, 3, 4))\n\n3.1415926535901235\n\n\nThat gives us a value pretty close to \\(\\pi\\), correct to the \\(11\\)th digit anyway.\n\n\nNewton-Raphson method\nThe Newton-Raphson method is a calculus-based method that iteratively steps towards a solution. Like the bisection method, it requires a number decided ahead of time but this time this chosen number is an initial guess or starting point. Unlike the bisection method, the Newton-Raphson method does not have bounds set on the search so a continuous function over the real numbers can be searched indefinitely. To prevent the algorithm searching for too long, a hyperparameter limiting the number of iterations (steps) is included if a stable solution is not converged upon (default is \\(50\\) steps).\n\nfrom scipy.optimize import newton\n# Define a single-variable function to find solutions in\n# try out the Newton-Raphson algorithm\nprint(newton(f, 0.2))\n\n3.6499361606787994e-14\n\n\nWhile \\(x = 0.2\\) is not that far off from Pi, the local derivatives are going to point the steps to descend toward zero. Notice that the solution we got was not exactly zero, but rather the first solution found within a predefined tolerance of \\(1.48 \\times 10^{-8}\\). What you don’t see from the code is the that shape of the curve, which if you plot our function you’ll see there is a local maxima between \\(x = 0\\) and \\(x = \\pi\\) at \\(x = \\frac{\\pi}{4}\\). Relative to this hill, our estimate is analogous to a ball rolling in the direction of steepest descent. This analogy breaks down for solutions separated by a local minima as the method is not equivalent to steepest descent even though it is based on the local derivative. Another issue that can come about is picking an initial value close to an extrema because the results can be unstable, allowing incredibly large jumps across the domain. Therefore, we should be cautious about our choice of initial guess by doing some exploration of function’s properties before attempting to estimate the solution. Let’s retry with a more suitable initial value.\n\n# try out the Newton-Raphson algorithm\nprint(newton(f, np.pi / 4 + 1))\n\n3.1415926535897936\n\n\nThat is clearly closer to \\(\\pi\\) than \\(3.6499361606787994 \\times 10^{-14}\\), and being accurate for the first \\(16\\) digits suggests that it was more precise than the bisection algorithm under these parameters.\n\n\nBrent’s method\nThe QuantEcon course points out that Bisection is more robust (stable) than Newton-Raphson’s method, but it is also slower. An alternative approach that balances this tradeoff is Brent’s method which includes bounds and garantees solutions for computable functions. Let’s give this approach a try on our function on \\([3, 4]\\).\n\nfrom scipy.optimize import brentq\n# try out the Brent's algorithm\nprint(brentq(f, 3, 4))\n\n3.141592653589788\n\n\nLooks like this estimation of \\(\\pi\\) was correct for the first \\(13\\) digits, which was better than Bisection but worse than Newton-Raphson.\n\n\nPerformance comparison with timeit\nLast of all, it would be interesting to compare the time performance of each of these solution-finding approaches. Let’s do that with timeit.\n\nfrom timeit import timeit\nprint(timeit(stmt='bisect(f, 3, 4)',\\\n    globals={'bisect':bisect, 'f':f},\\\n    number=100000) / 100000)\nprint(timeit(stmt='newton(f, np.pi / 4 + 1)',\\\n    globals={'newton':newton, 'f':f, 'np':np},\\\n    number=100000) / 100000)\nprint(timeit(stmt='brentq(f, 3, 4)',\\\n    globals={'brentq':brentq, 'f':f},\\\n    number=100000) / 100000)\n\n0.00010017173054002341\n0.0001319278220400156\n2.3580086980000487e-05\n\n\nWe find under this setup that the slowest algorithm was the Newton-Raphson’s method, followed by the bisection method by a factor of \\(\\frac{1}{5}\\), and final Brent’s method being about an order of magnitude faster! So Brent’s method gave us more accurate digits in the solution, at least for \\(x = \\pi\\), and also performed faster than the other two methods. Does this mean that Brent’s method is always the best method? Not necessarily. We should be open to the possibility of tradeoffs not discussed on QuantEcon, as well as there being a panoply of algorithms out available in code repositories."
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "Integrating Causal Inference Methods into Northern Health’s Analytics Work\n\n\nObjective: This talk aims to highlight the integration of modern causal inference methods into the decision-making processes at Northern Health (NH). I present a comprehensive approach to incorporate causal inference principles into NH’s analytics work, emphasizing the significance of causality in healthcare research and its alignment with NH’s mission, vision, and strategic plans.\nMethods: The presentation outlines our approach, which involves the development of a systematic causal model development process. These methods are designed to equip NH’s data scientists and researchers with the skills necessary to apply modern causal inference techniques effectively.\nResults: I discuss the theoretical foundations and the framework for integrating modern causal inference methodologies into NH’s projects. I highlight the general challenges and benefits of applying causal inference methods in healthcare research, including addressing incomplete or corrupted data, accounting for unmeasured confounds, and estimating heterogeneous treatment effects at the individual level. Finally, I will report on the current state of a project to estimate the causal impact of COVID-19 on a time series data set in NH.\nLessons Learned: Causality has deep roots in philosophy, and modern causal inference offers a rigorous framework to address the complexities of healthcare data analysis. I emphasize the critical distinction between causal inference and traditional statistics and demonstrate how misleading statistics can misguide decision-making. I stress that causal inference methodologies are in harmony with NH’s mission, vision, and strategic objectives, enhancing the quality of inferences drawn from healthcare data.\n\n\nA Friendly Introduction to Statistical Forecasting\nA Moosy Proposal: Estimating Average Direction of Moose Travel from Weak Information\nAdventures in Non-Negative Canonical Polyadic Decomposition\nHow Correlation Really Works\nIntroduction to Interval Arithmetic\nIntroduction to Using ARIMA\nExample of Training a SARIMAX Model\nReview of a Study Using SARIMAX Guest lecture: Relations and Graphs\nA Gentle Introduction to Geometric Deep Learning{:target=“_blank”}\n\n\n\n\nPractical Approaches to Faster and Leaner Python{:target=“_blank”}\n\n\n\n\nA Gentle Introduction to L-Systems{:target=“_blank”}\nEnumeration of Automorphism Orbits of Graphlets (HackSeq){:target=“_blank”}"
  }
]