{
  "hash": "21c93457186e8e06b94c05381d4705a0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"How to NaÃ¯vely Generate Autoregressive Time Series Data in Python\"\nauthor: \"Galen Seilis\"\ndate: \"2024-07-31\"\ncategories: [Python, Statistics, Stochastic Processes, Autoregressive, Time Series, Matplotlib, NumPy]\n---\n\n\nIn this post I will show you how to simulate an autoregressive (AR) process using Matplotlib and NumPy.\n\nFirst, let's define a function which pseudorandomly generates the data sequence. We'll set an intercept parameter to set a consistent offset of the series from zero, and a sequence of autoregressive coefficients. The order of the coefficients entails the lag order that they are each applied to, so if you want to skip a lag order you can just set it to zero. Some AR series are noisier than others, and you can set that level of noise using the `noise` parameter. In this model we assume that the noise is a stationary normal distribution:\n\n$$\\epsilon_t \\sim \\mathcal{N}(0,1)$$\n\nfor all $t$.\n\nThe following implementation is a generalization of [*Generate Fake Autoregressive Data*](https://www.pymc.io/projects/examples/en/latest/time_series/Forecasting_with_structural_timeseries.html#generate-fake-autoregressive-data) in which I have allowed for any number of time lags. I have also allowed a user-provided random number generator to be passed.\n\n::: {#2f5b1e2d .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom typing import List\n\ndef simulate_ar(\n    intercept: float,\n    coefs: List[float],\n    noise: float = 0.3,\n    warmup: int = 10,\n    steps: int = 200,\n    rng=None\n    ) -> np.ndarray:\n    \"\"\"Simulates an autoregressive (AR) time series.\n\n    Args:\n        intercept (float): The intercept term of the AR process.\n        coefs (List[float]): List of coefficients for the lagged terms.\n        noise (float, optional): The standard deviation of the Gaussian noise. Default is 0.3.\n        warmup (int, optional): Number of initial steps to discard to allow the process to stabilize. Default is 10.\n        steps (int, optional): Number of steps to simulate after the warmup period. Default is 200.\n\n    Returns:\n        np.ndarray: Simulated AR time series data of length `steps`.\n    \"\"\"\n    rng = np.random.default_rng() if rng is None else rng\n    max_lag = len(coefs)\n    draws = np.zeros(warmup + steps)\n    draws[:max_lag] = intercept\n    for step in range(max_lag, warmup + steps):\n        draws[step] = intercept + rng.normal(0, noise)\n        for lag, coef in enumerate(coefs, start=1):\n            draws[step] += coef * draws[step - lag]\n    return draws[warmup:]\n```\n:::\n\n\nLet us set a seed for reproducibility.\n\n::: {#415906a9 .cell execution_count=2}\n``` {.python .cell-code}\nRANDOM_SEED = 2018\nrng = np.random.default_rng(RANDOM_SEED)\n```\n:::\n\n\nNow let's choose some parameters.\n\n::: {#39eedd47 .cell execution_count=3}\n``` {.python .cell-code}\n# True parameters of the AR process\nintercept = 10\ncoefs = [-0.3, 0.1, -0.3]  # Example coefficients for AR process with 3 lags\n```\n:::\n\n\nNow let us simulate the AR process.\n\n::: {#dbf52de6 .cell execution_count=4}\n``` {.python .cell-code}\nar_data = simulate_ar(intercept, coefs, warmup=2018, steps=200, rng=rng)\n```\n:::\n\n\nFinally, let us plot the simulated data using Matplotlib.\n\n::: {#64334a97 .cell execution_count=5}\n``` {.python .cell-code}\nfig, ax = plt.subplots(figsize=(8, 3))\nax.set_title(\"Generated Autoregressive Timeseries\", fontsize=15)\nax.plot(ar_data)\nax.set_xlabel('Time')\nax.set_ylabel('Signal')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=779 height=299}\n:::\n:::\n\n\nThis implementation is not particularly efficient in terms of computing resources. Although performance is influenced by many things, a large factor is the presence of an ordinary `for` loop. Upon every iteration of the loop the Python interpreter will check that all types are still valid, which is a waste of computing resources when you can assume that they are. Perhaps I will write a more efficient function, but this example should be suitable for examples and tinkering for now.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}