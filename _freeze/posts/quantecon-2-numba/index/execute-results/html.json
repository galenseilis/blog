{
  "hash": "40f46e55623600032bef610adbc3be3c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"QuantEcon 1 Numba\"\nauthor: \"Galen Seilis\"\ndate: \"2019-04-09\"\ncategories: [Python, Scipy, NumPy, timeit, optimization, Numba]\n---\n\n\n# Introduction\n\n[Numba](http://numba.pydata.org/) is a Python library that provides an open source just-in-time compiler that allows a coder to mark selected parts of their code to be compiled for faster execution. As someone interested in computation at any scale, from calculating $13 \\times 19$ (mental arithmetic is not my *forte*) to analyzing the behaviour of tens of thousands of genes or hundreds of thousands of IP addresses. I am not one to squeeze every inch of performance out of something small that was only meant to run once as a proof of concept, but it can be worth speeding up tasks that are either huge or will be repeated.\n\nLet's get into how to use Numba -- hang on! Why not just use compiled languages like C, C++ or FORTRAN? Well, herein lies one of meta-problems of development that requires some optimization. Coding in Python is useful for quickly coding up proofs of concept, but properties like its dynamic typing slow it down compared to memory-managed code in C. Coding in C will give a faster execution for the same code, but will often require more time and degugging to get ready for deployment. Using Python with Numba is an attempt to get the best of both worlds, and in practice is not much slower than software compiled from well-written low-level languages.\n\n# JIT\n\nThe first way we can use Numba to speed up our code is by compiling a function so that future executions can use the compiled version, removing the need to compile at runtime. Let's take a function that gives us the first *n* Fibonnacci numbers, and see how it performs.\n\n::: {#17608b20 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nfrom timeit import timeit\n\ndef fib(n):\n    '''\n    Adjusted from:\n    https://lectures.quantecon.org/py/numba.html\n    https://en.wikipedia.org/wiki/Fibonacci_number\n    https://www.geeksforgeeks.org/program-for-nth-fibonacci-number/\n    '''\n\n    if n == 1:\n        return np.ones(1)\n    elif n > 1:\n        x = np.empty(n)\n        x[0] = 1\n        x[1] = 1\n        for i in range(2,n):\n            x[i] =  x[i-1] + x[i-2]\n        return x\n    else:\n        print('WARNING: Check validity of input.')\n\nprint(timeit('fib(10)', globals={'fib':fib}))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.0311123809988203\n```\n:::\n:::\n\n\nRunning the above code on my laptop gives around 2 seconds to run the function $1000000$ times according to timeit, which is reasonable for small $n$ but let's see if we can speed this up with the Numba's jit.\n\n::: {#1f51e49c .cell execution_count=2}\n``` {.python .cell-code}\nfrom numba import jit\nimport numpy as np\nfrom timeit import timeit\n\ndef fib(n):\n    '''\n    ARGUMENTS:\n    n: Max index to calculate Fibonacci numbers up to (int)\n    RETURNS\n    x: Array of Fibonnacci numbers (numpy.ndarray)\n\n    NOTES:\n    Adjusted from:\n    https://lectures.quantecon.org/py/numba.html\n    https://en.wikipedia.org/wiki/Fibonacci_number\n    https://www.geeksforgeeks.org/program-for-nth-fibonacci-number/\n    '''\n\n    if n == 1:\n        return np.ones(1)\n    elif n > 1:\n        x = np.empty(n)\n        x[0] = 1\n        x[1] = 1\n        for i in range(2,n):\n            x[i] =  x[i-1] + x[i-2]\n        return x\n    else:\n        print('WARNING: Check validity of input.')\n\nfib = jit(fib)\n\nprint(timeit('fib(10)', globals={'fib':fib}))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.6980576210007712\n```\n:::\n:::\n\n\nRunning the above code with jit brought the execution time down to about 0.7 seconds, which is faster than the original function.\n\n# Vectorizing\n\nAnother approach to speeding up code is vectorizing, where multiple operations are applied to each entry directly instead of producing multiple intermediate arrays as operations are applied. Originally I had wanted to use our `fib` function, but [I quickly learned](https://stackoverflow.com/questions/55564403/numba-indexing-error-typeerror-cant-index-at-0-in-i8) that it is not [vectorizable](https://numba.pydata.org/numba-doc/dev/user/vectorize.html) because it cannot be made into a [universal function](https://docs.scipy.org/doc/numpy/reference/ufuncs.html). For a function to be universal, it is necessary that they map scalars into scalers, and map arrays into arrays. With that in mind, we'll vectorize a suitable function to show how the time performance is improved. Let's start by timing the unvectorized function.\n\n```python\nimport numpy as np\nimport quantecon as qe\n\ndef f(x, y):\n    return np.exp(np.abs(x -y**3)) *  np.cos(x**2 + y**2)\n\n# generate data\ngrid = np.linspace(-3, 3, 1000)\nx, y = np.meshgrid(grid, grid)\n\nstart = qe.util.tic()\nf(x, y)\nend = qe.util.toc()\n```\n\nOn my machine the execution time was about $0.05$ seconds, which isn't half-bad by itself. Not let's run the same code in vectorized form.\n\n```python\nfrom numba import vectorize\nimport numpy as np\nimport quantecon as qe\n\n@vectorize\ndef f(x, y):\n    return np.exp(np.abs(x -y**3)) *  np.cos(x**2 + y**2)\n\n# generate data\ngrid = np.linspace(-3, 3, 1000)\nx, y = np.meshgrid(grid, grid)\n\nf(x,y) # precompile\n\nstart = qe.util.tic()\nf(x, y)\nend = qe.util.toc()\n```\n\nThis vectorized form took about $0.0042$ seconds to execute, which is about $12$ times faster! This is a clear demonstration that vectorizing functions is worthwhile as scalability becomes an issue.\n\nBecause the vectorization of this function means that each element of the array is calculated independently, we can further attempt to speed this calculation up by calculating elements in parallel! We do that by telling the decorator the element types (we'll use `float64`), and that the target is function should be done in parallel.\n\n```python\nfrom numba import vectorize\nimport numpy as np\nimport quantecon as qe\n\n@vectorize('float64(float64, float64)', target='parallel')\ndef f(x, y):\n    return np.exp(np.abs(x -y**3)) *  np.cos(x**2 + y**2)\n\n# generate data\ngrid = np.linspace(-3, 3, 1000)\nx, y = np.meshgrid(grid, grid)\n\nf(x,y) # precompile\n\nstart = qe.util.tic()\nf(x, y)\nend = qe.util.toc()\n```\n\nThis last acceleration to make the calculations parallel squeezed the execution time down to $0.0031$ seconds. This is only $0.0011$ seconds faster than without the parallel execution, but still a worthwhile addition to the toolkit for doing independent calculations.\n\n# Conclusion\n\nUsing Numba allows us an easy way to increase the performance of functions in Python without going to a lower-abstraction language such as C or FORTRAN. Some functions will be more suitable to `@jit` than `@vectorize` based on the type of operations and whether the function is universal (or can be made into a universal function). These accelerations in performance becomes increasingly valuable as the amount of data being processed becomes large!\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}